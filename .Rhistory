geom_boxplot(aes(y = especificidad, color = "Especificidad")) +
ggtitle("Especificidad vs Sensitividad (RF - Ampliado)") +
labs(x ="Punto de corte", y = "Valor") +
scale_color_manual(values = colors) +  theme(text = element_text(face = "bold", size = 11))
ggpubr::ggarrange(q, r, common.legend = TRUE)
ggsave('./charts/variacion_pto_corte.png')
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/XGBoost.RData")
modelos_actuales <- as.data.frame(read_excel("./ComparativaModelos.xlsx",
sheet = "xgboost"))
modelos_actuales$tasa <- as.numeric(modelos_actuales$tasa)
modelos_actuales$auc <- as.numeric(modelos_actuales$auc)
modelos_actuales
modelos_actuales$tipo <- c(rep("LOGISTICA", 10), rep("RED NEURONAL", 10), rep("BAGGING", 10), rep("RANDOM FOREST", 10),
rep("GBM", 10), rep("SVM", 30), rep("XGBOOST", 10))
modelos_actuales[modelos_actuales$tipo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ]$modelo <- with(modelos_actuales[modelos_actuales$tipo %in% c("XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ],
reorder(modelo,tasa, mean))
p <- ggplot(modelos_actuales[modelos_actuales$tipo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ], aes(x = modelo, y = tasa)) +
geom_boxplot(alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo") + theme(axis.text.x = element_text(angle = 45, vjust = 0.5), text = element_text(size=14, face = "bold"))
modelos_actuales[modelos_actuales$tipo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ]$modelo <- with(modelos_actuales[modelos_actuales$tipo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ],
reorder(modelo,tasa, mean))
p <- ggplot(modelos_actuales[modelos_actuales$tipo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ], aes(x = modelo, y = tasa)) +
geom_boxplot(alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo") + theme(axis.text.x = element_text(angle = 45, vjust = 0.5), text = element_text(size=14, face = "bold"))
modelos_actuales[modelos_actuales$tipo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ]$modelo <- with(modelos_actuales[modelos_actuales$tipo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ],
reorder(modelo,auc, mean))
modelos_actuales[modelos_actuales$tipo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ]$modelo <- with(modelos_actuales[modelos_actuales$tipo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ],
reorder(modelo,auc, mean))
q <- ggplot(modelos_actuales[modelos_actuales$tipo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ], aes(x = modelo, y = auc)) +
geom_boxplot(alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("AUC por modelo") + theme(axis.text.x = element_text(angle = 45, vjust = 0.5), text = element_text(size=14, face = "bold"))
ggpubr::ggarrange(p, q, common.legend = TRUE)
modelos_actuales[modelos_actuales$tipo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ]
modelos_actuales[modelos_actuales$tipo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ]$modelo <- with(modelos_actuales[modelos_actuales$tipo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ],
reorder(modelo,auc, mean))
q <- ggplot(modelos_actuales[modelos_actuales$tipo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ], aes(x = tipo, y = auc)) +
geom_boxplot(alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("AUC por modelo") + theme(axis.text.x = element_text(angle = 45, vjust = 0.5), text = element_text(size=14, face = "bold"))
modelos_actuales[modelos_actuales$tipo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ]$modelo <- with(modelos_actuales[modelos_actuales$tipo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ],
reorder(modelo,tasa, mean))
p <- ggplot(modelos_actuales[modelos_actuales$tipo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ], aes(x = tipo, y = tasa)) +
geom_boxplot(alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo") + theme(axis.text.x = element_text(angle = 45, vjust = 0.5), text = element_text(size=14, face = "bold"))
ggpubr::ggarrange(p, q, common.legend = TRUE)
modelos_actuales <- as.data.frame(read_excel("./ComparativaModelos.xlsx",
sheet = "xgboost"))
modelos_actuales$tasa <- as.numeric(modelos_actuales$tasa)
modelos_actuales$auc <- as.numeric(modelos_actuales$auc)
modelos_actuales$tipo <- c(rep("LOGISTICA", 10), rep("RED NEURONAL", 10), rep("BAGGING", 10), rep("RANDOM FOREST", 10),
rep("GBM", 10), rep("SVM", 30), rep("XGBOOST", 10))
modelos_actuales
modelos_actuales <- as.data.frame(read_excel("./ComparativaModelos.xlsx",
sheet = "xgboost"))
modelos_actuales$tasa <- as.numeric(modelos_actuales$tasa)
modelos_actuales$auc <- as.numeric(modelos_actuales$auc)
modelos_actuales$modelo <- c(rep("LOGISTICA", 10), rep("RED NEURONAL", 10), rep("BAGGING", 10), rep("RANDOM FOREST", 10),
rep("GBM", 10), rep("SVM", 30), rep("XGBOOST", 10))
modelos_actuales[modelos_actuales$modelo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ]$modelo <- with(modelos_actuales[modelos_actuales$modelo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ],
reorder(modelo,tasa, mean))
p <- ggplot(modelos_actuales[modelos_actuales$modelo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ], aes(x = modelo, y = tasa)) +
geom_boxplot(alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo") + theme(axis.text.x = element_text(angle = 45, vjust = 0.5), text = element_text(size=14, face = "bold"))
p
modelos_actuales
modelos_actuales <- as.data.frame(read_excel("./ComparativaModelos.xlsx",
sheet = "xgboost"))
modelos_actuales$tasa <- as.numeric(modelos_actuales$tasa)
modelos_actuales$auc <- as.numeric(modelos_actuales$auc)
modelos_actuales$modelo <- c(rep("LOGISTICA", 10), rep("RED NEURONAL", 10), rep("BAGGING", 10), rep("RANDOM FOREST", 10),
rep("GBM", 10), rep("SVM", 30), rep("XGBOOST", 10))
modelos_actuales[modelos_actuales$modelo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), "modelo"] <- with(modelos_actuales[modelos_actuales$modelo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ],
reorder(modelo,tasa, mean))
p <- ggplot(modelos_actuales[modelos_actuales$modelo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ], aes(x = modelo, y = tasa)) +
geom_boxplot(alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo") + theme(axis.text.x = element_text(angle = 45, vjust = 0.5), text = element_text(size=14, face = "bold"))
p
modelos_actuales
modelos_actuales <- as.data.frame(read_excel("./ComparativaModelos.xlsx",
sheet = "xgboost"))
modelos_actuales$tasa <- as.numeric(modelos_actuales$tasa)
modelos_actuales$auc <- as.numeric(modelos_actuales$auc)
modelos_actuales$modelo <- c(rep("LOGISTICA", 10), rep("RED NEURONAL", 10), rep("BAGGING", 10), rep("RANDOM FOREST", 10),
rep("GBM", 10), rep("SVM", 30), rep("XGBOOST", 10))
modelos_actuales$modelo <- with(modelos_actuales,
reorder(modelo,tasa, mean))
p <- ggplot(modelos_actuales[modelos_actuales$modelo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ], aes(x = modelo, y = tasa)) +
geom_boxplot(alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo") + theme(axis.text.x = element_text(angle = 45, vjust = 0.5), text = element_text(size=14, face = "bold"))
p
modelos_actuales$modelo <- with(modelos_actuales, reorder(modelo,auc, mean))
q <- ggplot(modelos_actuales[modelos_actuales$tipo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ], aes(x = tipo, y = auc)) +
geom_boxplot(alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("AUC por modelo") + theme(axis.text.x = element_text(angle = 45, vjust = 0.5), text = element_text(size=14, face = "bold"))
q
modelos_actuales$modelo <- with(modelos_actuales, reorder(modelo,auc, mean))
q <- ggplot(modelos_actuales[modelos_actuales$tipo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ], aes(x = modelo, y = auc)) +
geom_boxplot(alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("AUC por modelo") + theme(axis.text.x = element_text(angle = 45, vjust = 0.5), text = element_text(size=14, face = "bold"))
q
modelos_actuales
modelos_actuales$modelo <- with(modelos_actuales, reorder(modelo,auc, mean))
q <- ggplot(modelos_actuales[modelos_actuales$modelo %in% c("LOGISTICA", "XGBOOST", "GBM", "RANDOM FOREST", "BAGGING"), ], aes(x = modelo, y = auc)) +
geom_boxplot(alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("AUC por modelo") + theme(axis.text.x = element_text(angle = 45, vjust = 0.5), text = element_text(size=14, face = "bold"))
q
ggpubr::ggarrange(p, q)
ggsave('./charts/comparacion_final.png')
library(rpart.plot)
rpart(factor(target)~mortality_rsi+bmi+month.8+Age, data = surgical_dataset)
tree <- rpart(factor(target)~mortality_rsi+bmi+month.8+Age, data = surgical_dataset)
rpart.plot(tree)
tree <- rpart(factor(target)~mortality_rsi+bmi+month.8+Age, data = surgical_dataset, method = "class")
rpart.plot(tree)
tree <- rpart(factor(target)~., data = surgical_dataset, method = "class")
rpart.plot(tree)
tree <- rpart(factor(target)~mortality_rsi+bmi+month.8+Age, data = surgical_dataset, method = "class", xval=5)
tree <- rpart(factor(target)~mortality_rsi+bmi+month.8+Age, data = surgical_dataset, method = "class", xval=5, maxcompete=2)
rpart.plot(tree)
tree <- rpart(factor(target)~mortality_rsi+bmi+month.8+Age, data = surgical_dataset, method = "class", xval=5, cp=0.005)
rpart.plot(tree)
tree <- rpart(factor(target)~mortality_rsi+bmi+month.8+Age, data = surgical_dataset, method = "class", xval=5, cp=0.001)
rpart.plot(tree)
tree <- rpart(factor(target)~mortality_rsi+month.8, data = surgical_dataset, method = "class", xval=5, cp=0.005)
rpart.plot(tree)
tree <- rpart(factor(target)~mortality_rsi+month.8, data = surgical_dataset, method = "class", xval=5, max_depth=100)
tree <- rpart(factor(target)~mortality_rsi+month.8, data = surgical_dataset, method = "class", xval=5, maxdepth=100)
tree <- rpart(factor(target)~mortality_rsi+month.8, data = surgical_dataset, method = "class", xval=5, maxdepth=30)
rpart.plot(tree)
tree <- rpart(factor(target)~mortality_rsi+bmi+month.8+Age, data = surgical_dataset, method = "class", xval=5, maxdepth=30)
rpart.plot(tree)
table(surgical_dataset[, c("month.8", "target")])
surgical_dataset[surgical_dataset$month.8 == 1 & target == "Yes", ]
surgical_dataset[surgical_dataset$month.8 == 1 & surgical_dataset$target == "Yes", ]
surgical_dataset[surgical_dataset$month.8 == 1 & surgical_dataset$target == "Yes", ][1:100, ]
surgical_dataset[surgical_dataset$month.8 == 1 & surgical_dataset$target == "Yes", ][1:500, ]
surgical_dataset[surgical_dataset$month.8 == 1 & surgical_dataset$target == "Yes", ][1:500]
surgical_dataset[surgical_dataset$month.8 == 1 & surgical_dataset$target == "Yes", ]
surgical_dataset[surgical_dataset$month.8 == 1 & surgical_dataset$target == "Yes", ]
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/SeleccionVariables.RData")
candidato.aic
candidato.bic
ggpubr::ggarrange(imp1, imp2, common.legend = TRUE)
imp1 <- show_vars_importance(rf_modelo_aic, "Importancia variables (AIC)")
imp2 <- show_vars_importance(rf_modelo_bic, "Importancia variables (BIC)")
ggpubr::ggarrange(imp1, imp2, common.legend = TRUE)
library(dplyr)
imp1 <- show_vars_importance(rf_modelo_aic, "Importancia variables (AIC)")
imp2 <- show_vars_importance(rf_modelo_bic, "Importancia variables (BIC)")
ggpubr::ggarrange(imp1, imp2, common.legend = TRUE)
library(ggplot2)
imp1 <- show_vars_importance(rf_modelo_aic, "Importancia variables (AIC)")
imp2 <- show_vars_importance(rf_modelo_bic, "Importancia variables (BIC)")
ggpubr::ggarrange(imp1, imp2, common.legend = TRUE)
# ------------- XGboost ---------------
# Objetivo: elaborar el mejor modelo de XGboost de acuerdo
#           a los valores de prediccion obtenidos
# Autor: Alberto Fernandez Hernandez
#--- Librerias
suppressPackageStartupMessages({
library(data.table)    # Lectura de ficheros mucho mas rapido que read.csv
library(parallel)      # Paralelizacion de funciones (I)
library(doParallel)    # Paralelizacion de funciones (II)
library(caret)         # Recursive Feature Elimination
library(readxl)        # Lectura ficheros .xlsx
library(DescTools)     # Reordenacion de variales categoricas
library(ggrepel)       # Labels ggplot2
source("./librerias/librerias_propias.R")
})
#--- Creamos el cluster
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
#--- Lectura dataset depurado
surgical_dataset <- fread("./data/surgical_dataset_final.csv", data.table = FALSE)
surgical_dataset$target <- as.factor(surgical_dataset$target)
tree <- rpart(factor(target)~mortality_rsi+bmi+month.8+Age, data = surgical_dataset, method = "class", xval=5)
rpart.plot(tree)
tree <- rpart(factor(target)~mortality_rsi+bmi+month.8+Age, data = surgical_dataset, method = "class", xval=5, cp=0.002)
rpart.plot(tree)
tree <- rpart(factor(target)~mortality_rsi+bmi+month.8+Age, data = surgical_dataset, method = "class", xval=5, cp=0.001)
rpart.plot(tree)
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/SeleccionVariables.RData")
imp1 <- show_vars_importance(rf_modelo_aic, "Importancia variables (AIC)")
imp2 <- show_vars_importance(rf_modelo_bic, "Importancia variables (BIC)")
ggpubr::ggarrange(imp1, imp2, common.legend = TRUE)
top4_soloaic <- c("Age", "mortality_rsi", "ahrq_ccs", "bmi")
top4 <- c("Age", "mortality_rsi", "bmi", "month.8")
candidato.aic.top5 <- c("Age", "mortality_rsi", "bmi", "month.8", "ahrq_ccs")
candidato.bic.4 <- c("Age", "mortality_rsi", "bmi", "month.8", "baseline_osteoart")
candidato.bic.5 <- c("Age", "mortality_rsi", "bmi", "month.8", "ccsMort30Rate")
candidatos_4         <- list(candidato.rfe.lr.2, candidato.aic, candidato.bic, top4, top4_soloaic, candidato.rfe.rf,
candidato.bic.4, candidato.bic.5)
nombres_candidatos_4 <- c("RFE LR TOP 3", "AIC" , "BIC" , "AIC-BIC-TOP 4", "TOP4_SOLOAIC", "RFE RF TOP 5 (AIC TOP 5)",
"BIC (TOP 5 - baseline_osteoart)", "BIC (TOP 5 - ccsMort30Rate)")
union4 <- cruzada_logistica(surgical_dataset, target, candidatos_4, nombres_candidatos_4,
grupos = 5, repe = 5)
union4$modelo <- with(union4, reorder(modelo,tasa, mean))
t <- ggplot(union4, aes(x = modelo, y = tasa)) +
geom_boxplot() +
ggtitle("Comparacion (tasa fallos)") +
labs(color='Dataset')  +
theme(text = element_text(size=13, face = "bold"), axis.text.x = element_text(angle = 45, vjust = 0.8))
t
union4$modelo <- with(union4, reorder(modelo,auc, mean))
a <- ggplot(union4, aes(x = modelo, y = auc)) +
geom_boxplot() +
ggtitle("Comparacion (AUC)") +
labs(color='Dataset')  +
theme(text = element_text(size=13, face = "bold"), axis.text.x = element_text(angle = 45, vjust = 0.8))
a
ggpubr::ggarrange(t, a, common.legend = TRUE)
ggsave('./charts/01_feature_selection_comparacion_random_forest.png')
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/Depuracion.RData")
library(ggplot2)
ggplot(surgical_dataset, aes(x = dow, fill = factor(complication))) +
geom_bar() +
labs(x = 'Day of week', y = 'Nº patients') +
ggtitle('Complication distribution by day of week') +
theme_minimal() +
theme(
text = element_text(family = 'Helvetica')
) + geom_text(stat='count', aes(label=..count..), position = position_stack(vjust = 0.5), size = 2.5) +
theme(legend.position="bottom")
ggplot(surgical_dataset, aes(x = dow, fill = factor(complication))) +
geom_bar() +
labs(x = 'Day of week', y = 'Nº patients') +
ggtitle('Complication distribution by day of week') +
theme_minimal() +
theme(
text = element_text(family = 'Helvetica')
) + geom_text(stat='count', aes(label=..count..), position = position_stack(vjust = 0.5), size = 5) +
theme(legend.position="bottom")
ggplot(surgical_dataset, aes(x = dow, fill = factor(complication))) +
geom_bar() +
labs(x = 'Day of week', y = 'Nº patients') +
ggtitle('Complication distribution by day of week') +
theme_minimal() +
theme(
text = element_text(family = 'Helvetica')
) + geom_text(stat='count', aes(label=..count..), position = position_stack(vjust = 0.5), size = 3.5) +
theme(legend.position="bottom")
ggsave('./charts/dow.png')
ggplot(surgical_dataset, aes(x = month, fill = factor(complication))) +
geom_bar() +
labs(x = 'Month', y = 'Nº patients') +
ggtitle('Complication distribution by month') +
theme_minimal() +
theme(
text = element_text(family = 'Helvetica')
) + geom_text(stat='count', aes(label=..count..), position = position_stack(vjust = 0.5), size = 3.5) +
theme(legend.position="bottom")
ggsave('./charts/month.png')
ggplot(surgical_dataset, aes(x = month, fill = factor(complication))) +
geom_bar() +
labs(x = 'Month', y = 'Nº patients') +
ggtitle('Complication distribution by month') +
theme_minimal() +
theme(
text = element_text(family = 'Helvetica')
) + geom_text(stat='count', aes(label=..count..), position = position_stack(vjust = 0.5), size = 6) +
theme(legend.position="bottom")
ggsave('./charts/month.png')
ggplot(surgical_dataset, aes(x = dow, fill = factor(complication))) +
geom_bar() +
labs(x = 'Day of week', y = 'Nº patients') +
ggtitle('Complication distribution by day of week') +
theme_minimal() +
theme(
text = element_text(family = 'Helvetica')
) + geom_text(stat='count', aes(label=..count..), position = position_stack(vjust = 0.5), size = 3.5) +
theme(legend.position="bottom")
ggsave('./charts/dow.png')
ggplot(surgical_dataset, aes(x = dow, fill = factor(complication))) +
geom_bar() +
labs(x = 'Day of week', y = 'Nº patients') +
ggtitle('Complication distribution by day of week') +
theme_minimal() +
theme(
text = element_text(family = 'Helvetica')
) + geom_text(stat='count', aes(label=..count..), position = position_stack(vjust = 0.5), size =6) +
theme(legend.position="bottom")
ggsave('./charts/dow.png')
library(rpart.plot)
tree <- rpart(factor(target) ~ mortality_rsi+bmi+month.8+Age, data = surgical_dataset_final, method = "clas")
tree <- rpart(factor(target) ~ mortality_rsi+bmi+month.8+Age, data = surgical_dataset_final, method = "class")
rpart.plot(tree)
surgical_dataset_final[c(1:1000), ]
surgical_dataset_final[c(1:1000), "month.8"] <- 1
tree <- rpart(factor(target) ~ mortality_rsi+bmi+month.8+Age, data = surgical_dataset_final, method = "class")
rpart.plot(tree)
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/SeleccionVariables.RData")
surgical_dataset_final[c(1:150), "month.8"] <- 1
surgical_dataset[c(1:150), "month.8"] <- 1
tree <- rpart(factor(target) ~ mortality_rsi+bmi+month.8+Age, data = surgical_dataset_final, method = "class")
tree <- rpart(factor(target) ~ mortality_rsi+bmi+month.8+Age, data = surgical_dataset, method = "class")
rpart.plot(tree)
surgical_dataset[c(1:350), "month.8"] <- 1
tree <- rpart(factor(target) ~ mortality_rsi+bmi+month.8+Age, data = surgical_dataset, method = "class")
rpart.plot(tree)
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/SeleccionVariables.RData")
surgical_dataset[c(1:250), "month.8"] <- 1
tree <- rpart(factor(target) ~ mortality_rsi+bmi+month.8+Age, data = surgical_dataset, method = "class")
rpart.plot(tree)
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/SeleccionVariables.RData")
surgical_dataset[c(1:200), "month.8"] <- 1
tree <- rpart(factor(target) ~ mortality_rsi+bmi+month.8+Age, data = surgical_dataset, method = "class")
rpart.plot(tree)
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/SeleccionVariables.RData")
surgical_dataset[c(1:200), "month.8"] <- 0
tree <- rpart(factor(target) ~ mortality_rsi+bmi+month.8+Age, data = surgical_dataset, method = "class")
rpart.plot(tree)
surgical_dataset[c(1:250), "month.8"] <- 0
tree <- rpart(factor(target) ~ mortality_rsi+bmi+month.8+Age, data = surgical_dataset, method = "class")
rpart.plot(tree)
surgical_dataset[c(1:350), "month.8"] <- 0
tree <- rpart(factor(target) ~ mortality_rsi+bmi+month.8+Age, data = surgical_dataset, method = "class")
rpart.plot(tree)
surgical_dataset[c(1:1350), "month.8"] <- 0
tree <- rpart(factor(target) ~ mortality_rsi+bmi+month.8+Age, data = surgical_dataset, method = "class")
rpart.plot(tree)
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/SeleccionVariables.RData")
surgical_dataset[c(1:120), "month.8"] <- 1
tree <- rpart(factor(target) ~ mortality_rsi+bmi+month.8+Age, data = surgical_dataset, method = "class")
rpart.plot(tree)
surgical_dataset[c(1:122), "month.8"] <- 1
tree <- rpart(factor(target) ~ mortality_rsi+bmi+month.8+Age, data = surgical_dataset, method = "class")
rpart.plot(tree)
tree <- rpart(factor(target) ~ mortality_rsi+bmi+month.8+Age, data = surgical_dataset, method = "class", cp=0.05)
rpart.plot(tree)
surgical_dataset[c(1:125), "month.8"] <- 1
tree <- rpart(factor(target) ~ mortality_rsi+bmi+month.8+Age, data = surgical_dataset, method = "class")
rpart.plot(tree)
surgical_dataset[c(1:130), "month.8"] <- 1
tree <- rpart(factor(target) ~ mortality_rsi+bmi+month.8+Age, data = surgical_dataset, method = "class")
rpart.plot(tree)
surgical_dataset[c(1:140), "month.8"] <- 1
tree <- rpart(factor(target) ~ mortality_rsi+bmi+month.8+Age, data = surgical_dataset, method = "class")
surgical_dataset[c(1:140), "month.8"] <- 1
rpart.plot(tree)
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/SeleccionVariables.RData")
surgical_dataset[c(1:50), "month.8"]
surgical_dataset[c(1:50) & surgical_dataset$target == 0, "month.8"]
surgical_dataset[surgical_dataset$target == 0, "month.8"]
surgical_dataset[c(1:50) & surgical_dataset$target == "No", "month.8"]
surgical_dataset[c(1:50) & surgical_dataset$target == "No", "month.8"] <- 1
tree <- rpart(factor(target) ~ mortality_rsi+bmi+month.8+Age, data = surgical_dataset, method = "class")
rpart.plot(tree)
surgical_dataset$month.8
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/SeleccionVariables.RData")
surgical_dataset[surgical_dataset$target == "Yes", "month.8"]
tree <- rpart(factor(target) ~ mortality_rsi+bmi+month.8+Age, data = surgical_dataset, method = "class")
rpart.plot(tree)
set.seed(1); tree <- rpart(factor(target) ~ mortality_rsi+bmi+month.8+Age, data = surgical_dataset, method = "class")
rpart.plot(tree)
set.seed(1); tree <- rpart(factor(target) ~ mortality_rsi+bmi+Age+month.8, data = surgical_dataset, method = "class")
rpart.plot(tree)
tree <- rpart(factor(target) ~ mortality_rsi+bmi+Age+month.8, data = surgical_dataset, method = "class", surrogatestyle=1)
rpart.plot(tree)
surgical_dataset[surgical_dataset$target == "No", ][1:50, ]
surgical_dataset[surgical_dataset$target == "No", ][1:50, "month.8"] <- 1
tree <- rpart(factor(target) ~ mortality_rsi+bmi+Age+month.8, data = surgical_dataset, method = "class", surrogatestyle=1)
rpart.plot(tree)
surgical_dataset[surgical_dataset$target == "No", ][1:100, "month.8"] <- 1
tree <- rpart(factor(target) ~ mortality_rsi+bmi+Age+month.8, data = surgical_dataset, method = "class", surrogatestyle=1)
rpart.plot(tree)
surgical_dataset[surgical_dataset$target == "No", ][1:200, "month.8"] <- 1
tree <- rpart(factor(target) ~ mortality_rsi+bmi+Age+month.8, data = surgical_dataset, method = "class", surrogatestyle=1)
rpart.plot(tree)
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/SeleccionVariables.RData")
surgical_dataset[surgical_dataset$target == "No", ][1:160, "month.8"] <- 1
tree <- rpart(factor(target) ~ mortality_rsi+bmi+Age+month.8, data = surgical_dataset, method = "class", surrogatestyle=1)
rpart.plot(tree)
surgical_dataset[surgical_dataset$target == "No", ][1:165, "month.8"] <- 1
tree <- rpart(factor(target) ~ mortality_rsi+bmi+Age+month.8, data = surgical_dataset, method = "class", surrogatestyle=1)
rpart.plot(tree)
surgical_dataset[surgical_dataset$target == "No", ][1:170, "month.8"] <- 1
tree <- rpart(factor(target) ~ mortality_rsi+bmi+Age+month.8, data = surgical_dataset, method = "class", surrogatestyle=1)
rpart.plot(tree)
surgical_dataset[surgical_dataset$target == "No", ][1:180, "month.8"] <- 1
tree <- rpart(factor(target) ~ mortality_rsi+bmi+Age+month.8, data = surgical_dataset, method = "class", surrogatestyle=1)
rpart.plot(tree)
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/SeleccionVariables.RData")
surgical_dataset[surgical_dataset$target == "No", ][1:171, "month.8"] <- 1
tree <- rpart(factor(target) ~ mortality_rsi+bmi+Age+month.8, data = surgical_dataset, method = "class", surrogatestyle=1)
rpart.plot(tree)
surgical_dataset[surgical_dataset$target == "No", ][1:172, "month.8"] <- 1
tree <- rpart(factor(target) ~ mortality_rsi+bmi+Age+month.8, data = surgical_dataset, method = "class", surrogatestyle=1)
rpart.plot(tree)
surgical_dataset[surgical_dataset$target == "No", ][1:175, "month.8"] <- 1
tree <- rpart(factor(target) ~ mortality_rsi+bmi+Age+month.8, data = surgical_dataset, method = "class", surrogatestyle=1)
rpart.plot(tree)
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/SeleccionVariables.RData")
surgical_dataset[surgical_dataset$target == "No", ][1:60, "month.8"] <- 1
tree <- rpart(factor(target) ~ mortality_rsi+bmi+Age+month.8, data = surgical_dataset, method = "class", cp=0.005)
rpart.plot(tree)
surgical_dataset[surgical_dataset$target == "No", ][1:80, "month.8"] <- 1
tree <- rpart(factor(target) ~ mortality_rsi+bmi+Age+month.8, data = surgical_dataset, method = "class", cp=0.005)
rpart.plot(tree)
surgical_dataset[surgical_dataset$target == "No", ][1:90, "month.8"] <- 1
tree <- rpart(factor(target) ~ mortality_rsi+bmi+Age+month.8, data = surgical_dataset, method = "class", cp=0.005)
rpart.plot(tree)
surgical_dataset[surgical_dataset$target == "No", ][1:100, "month.8"] <- 1
tree <- rpart(factor(target) ~ mortality_rsi+bmi+Age+month.8, data = surgical_dataset, method = "class", cp=0.005)
rpart.plot(tree)
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/SeleccionVariables.RData")
tree <- rpart(factor(target) ~ ., data = surgical_dataset, method = "class")
rpart.plot(tree)
surgical_dataset[surgical_dataset$target == "No", ][1:200, "month.8"] <- 1
tree <- rpart(factor(target) ~ ., data = surgical_dataset, method = "class")
rpart.plot(tree)
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/PuntoDeCorte.RData")
#-- Modelo 2
var_modelo2 <- c("mortality_rsi", "bmi", "Age")
puntos_corte <- seq(0, 1, 0.5)
dataframe_puntos_corte_rf      <- data.frame()
dataframe_puntos_corte_bagging <- data.frame()
dataframe_puntos_corte_gbm     <- data.frame()
dataframe_puntos_corte_xgboost <- data.frame()
for(punto_corte in puntos_corte) {
result_rf <- resultadosrf(dataf=surgical_dataset,vardep=target,listconti=var_modelo2,mtry=2,ntree=2000,sampsize=1000,
nodesize=20,corte=punto_corte)
result_rf$AUC <- as.numeric(result_rf$AUC)
result_rf$tasa <- as.numeric(result_rf$tasa)
result_rf$pto_corte <- punto_corte
dataframe_puntos_corte_rf <- rbind(dataframe_puntos_corte_rf, result_rf)
print(punto_corte)
}
dataframe_puntos_corte_rf
var_modelo2
#-- Modelo 2
var_modelo2 <- c("mortality_rsi", "bmi", "month.8", "Age")
for(punto_corte in puntos_corte) {
result_rf <- resultadosrf(dataf=surgical_dataset,vardep=target,listconti=var_modelo2,mtry=2,ntree=2000,sampsize=1000,
nodesize=20,corte=punto_corte)
result_rf$AUC <- as.numeric(result_rf$AUC)
result_rf$tasa <- as.numeric(result_rf$tasa)
result_rf$pto_corte <- punto_corte
dataframe_puntos_corte_rf <- rbind(dataframe_puntos_corte_rf, result_rf)
print(punto_corte)
}
dataframe_puntos_corte_rf
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/SeleccionVariables.RData")
modelo_logistico <- glm(target~Age+mortality_rsi+month.8+bmi, data=surgical_dataset, family=binomial(link="logit"))
modelo_logistico$coefficients
surgical_dataset[surgical_dataset$target == "No", ][1:200, "month.8"] <- 1
tree <- rpart(factor(target) ~ Age+mortality_rsi+month.8+bmi, data = surgical_dataset, method = "class")
rpart.plot(tree)
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/SeleccionVariables.RData")
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/PuntoDeCorte.RData")
surgical_dataset[surgical_dataset$target == "No", ][1:"100", "month.8"] <- 1
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/PuntoDeCorte.RData")
surgical_dataset[surgical_dataset$target == "No", ][1:100, "month.8"] <- 1
tree <- rpart(factor(target) ~ Age+mortality_rsi+month.8+bmi, data = surgical_dataset, method = "class")
rpart.plot(tree)
surgical_dataset[surgical_dataset$target == "No", ][1:150, "month.8"] <- 1
tree <- rpart(factor(target) ~ Age+mortality_rsi+month.8+bmi, data = surgical_dataset, method = "class")
rpart.plot(tree)
surgical_dataset[surgical_dataset$target == "No", ][1:160, "month.8"] <- 1
tree <- rpart(factor(target) ~ Age+mortality_rsi+month.8+bmi, data = surgical_dataset, method = "class")
rpart.plot(tree)
surgical_dataset[surgical_dataset$target == "No", ][1:170, "month.8"] <- 1
tree <- rpart(factor(target) ~ Age+mortality_rsi+month.8+bmi, data = surgical_dataset, method = "class")
rpart.plot(tree)
surgical_dataset[surgical_dataset$target == "No", ][1:180, "month.8"] <- 1
rpart.plot(tree)
tree <- rpart(factor(target) ~ Age+mortality_rsi+month.8+bmi, data = surgical_dataset, method = "class")
rpart.plot(tree)
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/SeleccionVariables.RData")
# ------------- Seleccion de variables ---------------
# Objetivo: realizar una seleccion previa de variables empleando
# -> metodos step aic + bic
# -> rfe
# -> Por ultimo, elegir las variables candidatas por medio de glm
# Autor: Alberto Fernandez Hernandez
#--- Librerias
suppressPackageStartupMessages({
library(data.table)    # Lectura de ficheros mucho mas rapido que read.csv
library(parallel)      # Paralelizacion de funciones (I)
library(doParallel)    # Paralelizacion de funciones (II)
library(caret)         # Recursive Feature Elimination
library(ggplot2)       # Libreria grafica
source("./librerias/librerias_propias.R")
source("./librerias/funcion steprepetido binaria.R")
})
#--- Creamos el cluster
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
imp1 <- show_vars_importance(rf_modelo_aic, "Importancia variables (AIC)")
imp2 <- show_vars_importance(rf_modelo_bic, "Importancia variables (BIC)")
ggpubr::ggarrange(imp1, imp2, common.legend = TRUE)
exp(0.27)
exp(-0.36)
exp(-2)
exp(-55)
ggplot(surgical_dataset, aes(x = mortality_rsi, fill = factor(complication))) +
geom_boxplot() +
theme_minimal() + ggtitle("mortality_rsi boxplot by target") + theme(legend.position = "bottom")
ggplot(surgical_dataset, aes(x = mortality_rsi, fill = factor(target))) +
geom_boxplot() +
theme_minimal() + ggtitle("mortality_rsi boxplot by target") + theme(legend.position = "bottom")
exp(0.78)
exp(-1.38)
