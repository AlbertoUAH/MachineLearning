col = c('red', 'blue') , bty = "n", horiz = FALSE,
lty=1, cex = 0.75)
#-- Ampliamos entre 0 y 2000 arboles
plot(rfbis.2$err.rate[c(0:2000),1], type = 'l', col = 'red')
lines(rfbis.1$err.rate[c(0:2000),1], col = 'blue')
legend("topright", legend = c("5 variables","8 variables") ,
col = c('red', 'blue') , bty = "n", horiz = FALSE,
lty=1, cex = 0.75)
#-- Ampliamos entre 0 y 1000 arboles
plot(rfbis.2$err.rate[c(0:1000),1], type = 'l', col = 'red')
lines(rfbis.1$err.rate[c(0:1000),1], col = 'blue')
legend("topright", legend = c("5 variables","8 variables") ,
col = c('red', 'blue') , bty = "n", horiz = FALSE,
lty=1, cex = 0.75)
source("./librerias/librerias_propias.R")
source("./librerias/cruzada rf binaria.R")
n.trees <- 300
5854/5
sampsizes <- list(1, 100, 500, 1000, 2000, 3000, 4000, 4600)
nodesizes.1 <- list(5, 10, 20, 30, 40, 50, 100, 150, 200)
rm(rfbis.1.df)
rm(rfbis.2.df)
bagging_modelo1 <- tuneo_bagging(surgical_dataset, target = target,
lista.continua = var_modelo1,
nodesizes = nodesizes.1,
sampsizes = sampsizes, mtry = mtry.1,
ntree = n.trees, grupos = 5, repe = 5)
help("train")
nrow(surgical_dataset)
(replace) nrow(surgical_dataset)
if (replace) nrow(surgical_dataset) else ceiling(.632*nrow(surgical_dataset))
bagging_modelo1
unlist(bagging_modelo1)
as.data.frame(bagging_modelo1)
as.data.frame(bagging_modelo1)
data.frame(matrix(unlist(bagging_modelo1), nrow=length(bagging_modelo1), byrow=TRUE))
do.call(rbind.data.frame, bagging_modelo1)
bagging_modelo1 <- do.call(rbind.data.frame, bagging_modelo1)
View(bagging_modelo1)
print(ggplot(union, aes(x = modelo, y = tasa)) +
geom_boxplot(fill = fill, colour = line,
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo"))
View(bagging_modelo1)
print(ggplot(bagging_modelo1, aes(x = modelo, y = tasa)) +
geom_boxplot(fill = fill, colour = line,
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo"))
print(ggplot(bagging_modelo1, aes(x = modelo, y = tasa)) +
geom_boxplot(fill = "#4271AE", colour = "#1F3552",
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo"))
suppressPackageStartupMessages({
library(data.table)    # Lectura de ficheros mucho mas rapido que read.csv
library(parallel)      # Paralelizacion de funciones (I)
library(doParallel)    # Paralelizacion de funciones (II)
library(caret)         # Recursive Feature Elimination
library(randomForest)  # Seleccion del numero de arboles
library(readxl)        # Lectura de ficheros Excel
source("./librerias/librerias_propias.R")
})
n.trees <- 300
sampsizes <- list(1, 100, 500, 1000, 2000, 3000, 4600)
# Sampsize maximo: (k-1) * n => (4/5) * 5854 = 4683.2 ~ 4600 obs.
# Conclusion: sampsize maximo: 4600 obs. (de forma aproximada)
#--  Modelo 1
nodesizes.1 <- list(5, 10, 20, 30, 40, 50, 100)
bagging_modelo1 <- tuneo_bagging(surgical_dataset, target = target,
lista.continua = var_modelo1,
nodesizes = nodesizes.1,
sampsizes = sampsizes, mtry = mtry.1,
ntree = n.trees, grupos = 5, repe = 5)
n.trees <- 300
sampsizes <- list(1, 100, 500, 1000, 2000, 3000, 4600)
# Sampsize maximo: (k-1) * n => (4/5) * 5854 = 4683.2 ~ 4600 obs.
# Conclusion: sampsize maximo: 4600 obs. (de forma aproximada)
#--  Modelo 1
nodesizes.1 <- list(5, 10, 20, 30, 40, 50)
bagging_modelo1 <- tuneo_bagging(surgical_dataset, target = target,
lista.continua = var_modelo1,
nodesizes = nodesizes.1,
sampsizes = sampsizes, mtry = mtry.1,
ntree = n.trees, grupos = 5, repe = 5)
bagging_modelo1
strsplit(bagging_modelo1$modelo, '+')
strsplit(bagging_modelo1$modelo, '+', fixed = T)
strsplit(bagging_modelo1$modelo, '+', fixed = T)[1]
strsplit(bagging_modelo1$modelo, '+', fixed = T)[[1]]
strsplit(bagging_modelo1$modelo, '+', fixed = T)
strsplit(bagging_modelo1$modelo, '+', fixed = T)[2]
strsplit(bagging_modelo1$modelo, '+', fixed = T)[23]
strsplit(bagging_modelo1$modelo, '+', fixed = T)
unlist(strsplit(bagging_modelo1$modelo, '+', fixed = T))
list(strsplit(bagging_modelo1$modelo, '+', fixed = T))
list(strsplit(bagging_modelo1$modelo, '+', fixed = T))[1]
data.frame(strsplit(bagging_modelo1$modelo, '+', fixed = T))
data.frame(strsplit(bagging_modelo1$modelo, '+', fixed = T))[1,]
data.frame(strsplit(bagging_modelo1$modelo, '+', fixed = T))[2,]
bagging_modelo1$nodesizes <- data.frame(strsplit(bagging_modelo1$modelo, '+', fixed = T))[1,]
bagging_modelo1$sampsizes <- data.frame(strsplit(bagging_modelo1$modelo, '+', fixed = T))[2,]
unlist(data.frame(strsplit(bagging_modelo1$modelo, '+', fixed = T))[1,])
c(data.frame(strsplit(bagging_modelo1$modelo, '+', fixed = T))[1,])
bagging_modelo1$nodesizes <- c(data.frame(strsplit(bagging_modelo1$modelo, '+', fixed = T))[1,])
View(bagging_modelo1)
bagging_modelo1$sampsizes <- c(data.frame(strsplit(bagging_modelo1$modelo, '+', fixed = T))[2,])
View(bagging_modelo1)
ggplot(bagging_modelo1, aes(x=factor(nodesizes), y=auc,
colour=factor(sampsizes))) +
geom_point(position=position_dodge(width=0.5),size=3)
sapply(bagging_modelo1, class)
as.numeric(c(data.frame(strsplit(bagging_modelo1$modelo, '+', fixed = T))[1,]))
bagging_modelo1$nodesizes <- as.numeric(c(data.frame(strsplit(bagging_modelo1$modelo, '+', fixed = T))[1,]))
bagging_modelo1$sampsizes <- as.numeric(c(data.frame(strsplit(bagging_modelo1$modelo, '+', fixed = T))[2,]))
ggplot(bagging_modelo1, aes(x=factor(nodesizes), y=auc,
colour=factor(sampsizes))) +
geom_point(position=position_dodge(width=0.5),size=3)
ggplot(bagging_modelo1, aes(x=factor(sampsizes), y=auc,
colour=factor(nodesizes))) +
geom_point(position=position_dodge(width=0.5),size=3)
ggplot(bagging_modelo1, aes(x=factor(sampsizes), y=auc,
colour=factor(nodesizes))) +
geom_point(position=position_dodge(width=0.3),size=3)
ggplot(bagging_modelo1, aes(x=factor(sampsizes), y=auc,
colour=factor(nodesizes))) +
geom_point(position=position_dodge(width=0.3),size=3, aes(size = 0.3))
ggplot(bagging_modelo1, aes(x=factor(sampsizes), y=auc,
colour=factor(nodesizes))) +
geom_point(position=position_dodge(width=0.3),size=3, aes(size = 0.1))
ggplot(bagging_modelo1, aes(x=factor(sampsizes), y=auc,
colour=factor(nodesizes))) +
geom_point(position=position_dodge(width=0.3),size=3, shape = 21)
ggplot(bagging_modelo1, aes(x=factor(sampsizes), y=auc,
colour=factor(nodesizes))) +
geom_point(position=position_dodge(width=0.3),size=3, shape = 4)
ggplot(bagging_modelo1, aes(x=factor(sampsizes), y=auc,
colour=factor(nodesizes))) +
geom_point(position=position_dodge(width=0.3),size=3, shape = 3)
ggplot(bagging_modelo1, aes(x=factor(sampsizes), y=auc,
colour=factor(nodesizes))) +
geom_point(position=position_dodge(width=0.3),size=3, shape = 2)
ggplot(bagging_modelo1, aes(x=factor(sampsizes), y=auc,
colour=factor(nodesizes))) +
geom_point(position=position_dodge(width=0.3),size=3, shape = 5)
ggplot(bagging_modelo1, aes(x=factor(sampsizes), y=auc,
colour=factor(nodesizes))) +
geom_point(position=position_dodge(width=0.3),size=3, shape = 1)
ggplot(bagging_modelo1, aes(x=factor(sampsizes), y=auc,
colour=factor(nodesizes))) +
geom_point(position=position_dodge(width=0.3),size=3, shape = 14)
ggplot(bagging_modelo1, aes(x=factor(sampsizes), y=auc,
colour=factor(nodesizes))) +
geom_point(position=position_dodge(width=0.3),size=3, shape = 18)
ggplot(bagging_modelo1, aes(x=factor(sampsizes), y=auc,
colour=factor(nodesizes))) +
geom_point(position=position_dodge(width=0.3),size=3, shape = 18)
bagging_modelo1[bagging_modelo1$sampsizes == 4000, ]
bagging_modelo1[bagging_modelo1$sampsizes == 4000, ] <- NULL
bagging_modelo1[~bagging_modelo1$sampsizes == 4000, ]
bagging_modelo1[!bagging_modelo1$sampsizes == 4000, ]
bagging_modelo1[bagging_modelo1$sampsizes == 4000, ]
bagging_modelo1 <- bagging_modelo1[!bagging_modelo1$sampsizes == 4000, ]
bagging_modelo1 <- bagging_modelo1[!bagging_modelo1$nodesizes == 200, ]
ggplot(bagging_modelo1, aes(x=factor(sampsizes), y=auc,
colour=factor(nodesizes))) +
geom_point(position=position_dodge(width=0.3),size=3, shape = 18)
rm(sampsizes)
sampsizes.1 <- list(1, 100, 500, 1000, 2000, 3000, 4600)
nodesizes.1 <- list(20)
sampsizes.1 <- list(1, 500, 1000, 2000, 3000, 4600)
bagging_modelo1_2 <- tuneo_bagging(surgical_dataset, target = target,
lista.continua = var_modelo1,
nodesizes = nodesizes.1,
sampsizes = sampsizes.1, mtry = mtry.1,
ntree = n.trees, grupos = 5, repe = 5)
ggplot(bagging_modelo1, aes(x=factor(sampsizes), y=tasa,
colour=factor(nodesizes))) +
geom_point(position=position_dodge(width=0.3),size=3, shape = 18)
nodesizes.1 <- list(20)
sampsizes.1 <- list(1, 500, 1000, 2000, 3000, 4600)
bagging_modelo1_2 <- tuneo_bagging(surgical_dataset, target = target,
lista.continua = var_modelo1,
nodesizes = nodesizes.1,
sampsizes = sampsizes.1, mtry = mtry.1,
ntree = n.trees, grupos = 5, repe = 5)
#-- Funciones propias
suppressPackageStartupMessages({
library(DataExplorer)  # EDAs automaticos
library(gridExtra)     # Representar tablas graficamente
library(ggplot2)       # Libreria grafica
source("./librerias/cruzadas avnnet y log binaria.R")
source("./librerias/cruzada rf binaria.R")
})
# libreria para EDA
make_eda_report <- function(df, target, title, file_name, path) {
create_report(df,
y = target,
report_title = title,
output_file = file_name,
output_dir = path)
}
# tuneo regresion logistica
cruzada_logistica <- function(dataset, target, candidatos, nombres_candidatos, grupos, repe) {
union  <- data.frame(tasa = numeric(), auc = numeric(), modelo = character())
for (i in seq(1, length(candidatos))) {
medias <- cruzadalogistica(data=dataset, vardep=target,
listconti=candidatos[[i]], listclass=c(""),
grupos=grupos,sinicio=1234,repe=repe)
medias.df <- data.frame(medias[1])
medias.df$modelo <- nombres_candidatos[i]
union <- rbind(union, medias.df)
print(paste0(nombres_candidatos[i], ": completed!"))
}
fill <- "#4271AE"
line <- "#1F3552"
print(ggplot(union, aes(x = modelo, y = tasa)) +
geom_boxplot(fill = fill, colour = line,
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo"))
print(ggplot(union, aes(x = modelo, y = auc)) +
geom_boxplot(fill = fill, colour = line,
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("AUC por modelo"))
return(union)
}
# Funcion para obtener la matriz de confusion de las predicciones resultantes
matriz_confusion_predicciones <- function(modelo = "glm", formula, dataset, corte) {
if (modelo == "glm") {
modelo <- glm(formula,
data = dataset,
family = binomial(link="logit")
)
}
pred <- predict(modelo, dataset, type = "prob")
pred_vector <- as.factor(ifelse(
pred$No > corte,
"No",
"Yes"
))
matriz_confusion <- confusionMatrix(dataset$target, pred_vector)
return(matriz_confusion)
}
# comparacion modelos redes neuronales
comparar_modelos_red <- function(dataset, target, lista.continua, sizes,
decays, grupos, repe, iteraciones) {
union  <- data.frame(tasa = numeric(), auc = numeric(), modelo = character())
for (i in seq(1:length(sizes))) {
cvnnet.candidato <- cruzadaavnnetbin(data=dataset,vardep=target,
listconti=lista.continua,
listclass=c(""),
grupos=grupos,sinicio=1234,
repe=repe, size=sizes[i],
decay=decays[i],repeticiones=repe,
itera=iteraciones)
modelo <- paste0("NODOS: ", sizes[i] , " - DECAY: ", decays[i])
medias.df <- data.frame(cvnnet.candidato[1])
medias.df$modelo <- paste0(modelo)
union <- rbind(union, medias.df)
print(paste0(modelo, ": completed!"))
}
fill <- "#4271AE"
line <- "#1F3552"
print(ggplot(union, aes(x = modelo, y = tasa)) +
geom_boxplot(fill = fill, colour = line,
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo"))
print(ggplot(union, aes(x = modelo, y = auc)) +
geom_boxplot(fill = fill, colour = line,
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("AUC por modelo"))
return(union)
}
# Funcion para el tuneo de un modelo bagging
tuneo_bagging <- function(dataset, target, lista.continua, nodesizes, sampsizes,
mtry, ntree, grupos, repe) {
lista.rf <- list()
for(x in apply(data.frame(expand.grid(nodesizes, sampsizes)),1,as.list)) {
salida <- cruzadarfbin(data=dataset, vardep=target,
listconti=lista.continua,
listclass=c(""),
grupos=grupos,sinicio=1234,repe=repe,nodesize=x$Var1,
mtry=mtry,ntree=ntree, sampsize=x$Var2)
cat(x$Var1, "+",  x$Var2 , "-> FINISHED\n")
salida$modelo <- paste0(x$Var1, "+",  x$Var2)
lista.rf <- c(lista.rf, list(salida))
}
union <- do.call(rbind.data.frame, bagging_modelo1)
fill <- "#4271AE"
line <- "#1F3552"
print(colnames(union))
print(ggplot(union, aes(x = modelo, y = tasa)) +
geom_boxplot(fill = fill, colour = line,
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo"))
print(ggplot(union, aes(x = modelo, y = auc)) +
geom_boxplot(fill = fill, colour = line,
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("AUC por modelo"))
return(union)
}
nodesizes.1 <- list(20)
sampsizes.1 <- list(1, 500, 1000, 2000, 3000, 4600)
bagging_modelo1_2 <- tuneo_bagging(surgical_dataset, target = target,
lista.continua = var_modelo1,
nodesizes = nodesizes.1,
sampsizes = sampsizes.1, mtry = mtry.1,
ntree = n.trees, grupos = 5, repe = 5)
#-- Funciones propias
suppressPackageStartupMessages({
library(DataExplorer)  # EDAs automaticos
library(gridExtra)     # Representar tablas graficamente
library(ggplot2)       # Libreria grafica
source("./librerias/cruzadas avnnet y log binaria.R")
source("./librerias/cruzada rf binaria.R")
})
# libreria para EDA
make_eda_report <- function(df, target, title, file_name, path) {
create_report(df,
y = target,
report_title = title,
output_file = file_name,
output_dir = path)
}
# tuneo regresion logistica
cruzada_logistica <- function(dataset, target, candidatos, nombres_candidatos, grupos, repe) {
union  <- data.frame(tasa = numeric(), auc = numeric(), modelo = character())
for (i in seq(1, length(candidatos))) {
medias <- cruzadalogistica(data=dataset, vardep=target,
listconti=candidatos[[i]], listclass=c(""),
grupos=grupos,sinicio=1234,repe=repe)
medias.df <- data.frame(medias[1])
medias.df$modelo <- nombres_candidatos[i]
union <- rbind(union, medias.df)
print(paste0(nombres_candidatos[i], ": completed!"))
}
fill <- "#4271AE"
line <- "#1F3552"
print(ggplot(union, aes(x = modelo, y = tasa)) +
geom_boxplot(fill = fill, colour = line,
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo"))
print(ggplot(union, aes(x = modelo, y = auc)) +
geom_boxplot(fill = fill, colour = line,
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("AUC por modelo"))
return(union)
}
# Funcion para obtener la matriz de confusion de las predicciones resultantes
matriz_confusion_predicciones <- function(modelo = "glm", formula, dataset, corte) {
if (modelo == "glm") {
modelo <- glm(formula,
data = dataset,
family = binomial(link="logit")
)
}
pred <- predict(modelo, dataset, type = "prob")
pred_vector <- as.factor(ifelse(
pred$No > corte,
"No",
"Yes"
))
matriz_confusion <- confusionMatrix(dataset$target, pred_vector)
return(matriz_confusion)
}
# comparacion modelos redes neuronales
comparar_modelos_red <- function(dataset, target, lista.continua, sizes,
decays, grupos, repe, iteraciones) {
union  <- data.frame(tasa = numeric(), auc = numeric(), modelo = character())
for (i in seq(1:length(sizes))) {
cvnnet.candidato <- cruzadaavnnetbin(data=dataset,vardep=target,
listconti=lista.continua,
listclass=c(""),
grupos=grupos,sinicio=1234,
repe=repe, size=sizes[i],
decay=decays[i],repeticiones=repe,
itera=iteraciones)
modelo <- paste0("NODOS: ", sizes[i] , " - DECAY: ", decays[i])
medias.df <- data.frame(cvnnet.candidato[1])
medias.df$modelo <- paste0(modelo)
union <- rbind(union, medias.df)
print(paste0(modelo, ": completed!"))
}
fill <- "#4271AE"
line <- "#1F3552"
print(ggplot(union, aes(x = modelo, y = tasa)) +
geom_boxplot(fill = fill, colour = line,
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo"))
print(ggplot(union, aes(x = modelo, y = auc)) +
geom_boxplot(fill = fill, colour = line,
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("AUC por modelo"))
return(union)
}
# Funcion para el tuneo de un modelo bagging
tuneo_bagging <- function(dataset, target, lista.continua, nodesizes, sampsizes,
mtry, ntree, grupos, repe) {
lista.rf <- list()
for(x in apply(data.frame(expand.grid(nodesizes, sampsizes)),1,as.list)) {
salida <- cruzadarfbin(data=dataset, vardep=target,
listconti=lista.continua,
listclass=c(""),
grupos=grupos,sinicio=1234,repe=repe,nodesize=x$Var1,
mtry=mtry,ntree=ntree, sampsize=x$Var2)
cat(x$Var1, "+",  x$Var2 , "-> FINISHED\n")
salida$modelo <- paste0(x$Var1, "+",  x$Var2)
lista.rf <- c(lista.rf, list(salida))
}
union <- do.call(rbind.data.frame, lista.rf)
fill <- "#4271AE"
line <- "#1F3552"
print(colnames(union))
print(ggplot(union, aes(x = modelo, y = tasa)) +
geom_boxplot(fill = fill, colour = line,
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo"))
print(ggplot(union, aes(x = modelo, y = auc)) +
geom_boxplot(fill = fill, colour = line,
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("AUC por modelo"))
return(union)
}
nodesizes.1 <- list(20)
sampsizes.1 <- list(1, 500, 1000, 2000, 3000, 4600)
bagging_modelo1_2 <- tuneo_bagging(surgical_dataset, target = target,
lista.continua = var_modelo1,
nodesizes = nodesizes.1,
sampsizes = sampsizes.1, mtry = mtry.1,
ntree = n.trees, grupos = 5, repe = 5)
nodesizes.1 <- list(50)
sampsizes.1 <- list(1, 500, 1000, 2000, 3000, 4600)
bagging_modelo1_2 <- tuneo_bagging(surgical_dataset, target = target,
lista.continua = var_modelo1,
nodesizes = nodesizes.1,
sampsizes = sampsizes.1, mtry = mtry.1,
ntree = n.trees, grupos = 5, repe = 5)
nodesizes.1 <- list(50)
sampsizes.1 <- list(1, 500, 1000, 2000, 3000, 4600)
bagging_modelo1_3 <- tuneo_bagging(surgical_dataset, target = target,
lista.continua = var_modelo1,
nodesizes = nodesizes.1,
sampsizes = sampsizes.1, mtry = mtry.1,
ntree = n.trees, grupos = 5, repe = 5)
View(bagging_modelo1_2)
save.image("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/Bagging.RData")
nodesizes.1 <- list(50)
sampsizes.1 <- list(1, 500, 1000, 2000, 3000, 4600)
bagging_modelo1_3 <- tuneo_bagging(surgical_dataset, target = target,
lista.continua = var_modelo1,
nodesizes = nodesizes.1,
sampsizes = sampsizes.1, mtry = mtry.1,
ntree = n.trees, grupos = 5, repe = 5)
suppressPackageStartupMessages({
library(data.table)    # Lectura de ficheros mucho mas rapido que read.csv
library(parallel)      # Paralelizacion de funciones (I)
library(doParallel)    # Paralelizacion de funciones (II)
library(caret)         # Recursive Feature Elimination
library(randomForest)  # Seleccion del numero de arboles
library(readxl)        # Lectura de ficheros Excel
source("./librerias/librerias_propias.R")
})
nodesizes.1 <- list(50)
sampsizes.1 <- list(1, 500, 1000, 2000, 3000, 4600)
bagging_modelo1_3 <- tuneo_bagging(surgical_dataset, target = target,
lista.continua = var_modelo1,
nodesizes = nodesizes.1,
sampsizes = sampsizes.1, mtry = mtry.1,
ntree = n.trees, grupos = 5, repe = 5)
nodesizes.1 <- list(50)
sampsizes.1 <- list(1, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4600)
bagging_modelo1_3 <- tuneo_bagging(surgical_dataset, target = target,
lista.continua = var_modelo1,
nodesizes = nodesizes.1,
sampsizes = sampsizes.1, mtry = mtry.1,
ntree = n.trees, grupos = 5, repe = 5)
nodesizes.1 <- list(20)
sampsizes.1 <- list(1, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4600)
bagging_modelo1_2 <- tuneo_bagging(surgical_dataset, target = target,
lista.continua = var_modelo1,
nodesizes = nodesizes.1,
sampsizes = sampsizes.1, mtry = mtry.1,
ntree = n.trees, grupos = 5, repe = 5)
ggplot(bagging_modelo1, aes(x=factor(sampsizes), y=tasa,
colour=factor(nodesizes))) +
geom_point(position=position_dodge(width=0.3),size=3, shape = 18)
#-- Distribucion del AUC
#  Parece buen candidato 20 nodeszie y sampsize todos salvo 100
ggplot(bagging_modelo1, aes(x=factor(sampsizes), y=auc,
colour=factor(nodesizes))) +
geom_point(position=position_dodge(width=0.3),size=3, shape = 18)
nodesizes.1 <- list(100)
sampsizes.1 <- list(1, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4600)
bagging_modelo1_4 <- tuneo_bagging(surgical_dataset, target = target,
lista.continua = var_modelo1,
nodesizes = nodesizes.1,
sampsizes = sampsizes.1, mtry = mtry.1,
ntree = n.trees, grupos = 5, repe = 5)
save.image("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/Bagging.RData")
