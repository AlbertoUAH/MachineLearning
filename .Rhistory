bagging_2_2
bagging_2_2$modelInfo
bagging_2_2
bagging_2_2$finalModel
matriz_conf_2_2 <- matriz_confusion_predicciones(bagging_2_2, NULL, surgical_test_data, 0.5)
matriz_conf_2_2
matriz_conf_2
#-- Modelos finales
#   Modelo 1
bagging_1_1$finalModel
#   Modelo 2
bagging_2_1$finalModel
union_bagging_modelo1
union_bagging_modelo2
union_bagging_modelo1
surgical_test_data <- fread("./data/surgical_test_data.csv", data.table = FALSE)
names(surgical_test_data)[35] <- "target"
surgical_test_data$target     <- as.factor(surgical_test_data$target)
matriz_conf_1 <- matriz_confusion_predicciones(bagging_1_1, NULL, surgical_test_data, 0.5)
matriz_conf_1_2 <- matriz_confusion_predicciones(bagging_1_2, NULL, surgical_test_data, 0.5)
matriz_conf_2 <- matriz_confusion_predicciones(bagging_2_1, NULL, surgical_test_data, 0.5)
matriz_conf_2_2 <- matriz_confusion_predicciones(bagging_2_2, NULL, surgical_test_data, 0.5)
modelos_actuales <- as.data.frame(read_excel("./ComparativaModelos.xlsx",
sheet = "random_forest"))
modelos_actuales$tasa <- as.numeric(modelos_actuales$tasa)
modelos_actuales$auc <- as.numeric(modelos_actuales$auc)
bagging_modelo_sin_reemp <- tuneo_bagging(surgical_dataset, target = target,
lista.continua = var_modelo1,
nodesizes = 20,
sampsizes = 1000, mtry = 3,
ntree = 2000, grupos = 5, repe = 10, replace = FALSE)
bagging_modelo_sin_reemp$modelo <- "RF. MODELO 1 (no reemp)"
modelos_actuales <- rbind(modelos_actuales, bagging_modelo_sin_reemp)
bagging_modelo_sin_reemp <- tuneo_bagging(surgical_dataset, target = target,
lista.continua = var_modelo1,
nodesizes = 20,
sampsizes = 1000, mtry = 3,
ntree = 2000, grupos = 5, repe = 10, replace = FALSE)
#---- Detenemos el cluster
stopCluster(cluster)
# ------------- Random Forest ---------------
# Objetivo: elaborar el mejor modelo de Random Forest de acuerdo
#           a los valores de prediccion obtenidos tras variar los parametros
#           sampsize, nodesize y mtry
# Autor: Alberto Fernandez Hernandez
#--- Librerias
suppressPackageStartupMessages({
library(data.table)    # Lectura de ficheros mucho mas rapido que read.csv
library(parallel)      # Paralelizacion de funciones (I)
library(doParallel)    # Paralelizacion de funciones (II)
library(caret)         # Recursive Feature Elimination
library(randomForest)  # Seleccion del numero de arboles
library(readxl)        # Lectura de ficheros Excel
source("./librerias/librerias_propias.R")
})
#--- Creamos el cluster
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
modelos_actuales <- as.data.frame(read_excel("./ComparativaModelos.xlsx",
sheet = "random_forest"))
modelos_actuales$tasa <- as.numeric(modelos_actuales$tasa)
modelos_actuales$auc <- as.numeric(modelos_actuales$auc)
#-- Â¿Y si lo probamos sin reemplazamiento? Probamos con el mejor modelo en terminos de AUC (modelo 1)
bagging_modelo_sin_reemp <- tuneo_bagging(surgical_dataset, target = target,
lista.continua = var_modelo1,
nodesizes = 20,
sampsizes = 1000, mtry = 3,
ntree = 2000, grupos = 5, repe = 10, replace = FALSE)
bagging_modelo_sin_reemp$modelo <- "RF. MODELO 1 (no reemp)"
modelos_actuales <- rbind(modelos_actuales, bagging_modelo_sin_reemp)
modelos_actuales$modelo <- with(modelos_actuales,
reorder(modelo,tasa, mean))
ggplot(modelos_actuales, aes(x = modelo, y = tasa)) +
geom_boxplot(fill =  "#4271AE", colour = "#1F3552",
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo")
ggsave('./charts/comparativas/03_log_avnnet_bagging_rf_tasa.jpeg')
modelos_actuales_zoomed$modelo <- with(modelos_actuales_zoomed,
reorder(modelo,auc, mean))
ggplot(modelos_actuales_zoomed, aes(x = modelo, y = auc)) +
geom_boxplot(fill =  "#4271AE", colour = "#1F3552",
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("AUC por modelo (solo BAGGING)")
ggsave('./charts/random_forest/03_FINAL_auc.jpeg')
modelos_actuales$modelo <- with(modelos_actuales,
reorder(modelo,auc, mean))
ggplot(modelos_actuales, aes(x = modelo, y = auc)) +
geom_boxplot(fill =  "#4271AE", colour = "#1F3552",
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("AUC por modelo")
ggsave('./charts/comparativas/03_log_avnnet_bagging_rf_auc.jpeg')
#-- Si hacemos zoom sobre los modelos bagging y rf...
modelos_actuales_zoomed <- modelos_actuales[modelos_actuales$modelo %in% c("BAG. MODELO 1", "BAG. MODELO 2", "RF. MODELO 1",
"RF. MODELO 2", "RF. MODELO 1 (no reemp)"), ]
modelos_actuales_zoomed$modelo <- with(modelos_actuales_zoomed,
reorder(modelo,tasa, mean))
ggplot(modelos_actuales_zoomed, aes(x = modelo, y = tasa)) +
geom_boxplot(fill =  "#4271AE", colour = "#1F3552",
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo (solo BAGGING)")
ggsave('./charts/random_forest/03_FINAL_tasa.jpeg')
modelos_actuales_zoomed$modelo <- with(modelos_actuales_zoomed,
reorder(modelo,auc, mean))
ggplot(modelos_actuales_zoomed, aes(x = modelo, y = auc)) +
geom_boxplot(fill =  "#4271AE", colour = "#1F3552",
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("AUC por modelo (solo BAGGING)")
ggsave('./charts/random_forest/03_FINAL_auc.jpeg')
#---- Detenemos el cluster
stopCluster(cluster)
#---- Guardamos el fichero RData
save.image(file = "./rdata/RandomForest.RData")
save.image("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/RandomForest.RData")
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/Bagging.RData")
union_bagging_modelo1
union_bagging_modelo2
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/GradientBoosting.RData")
plot(gbm_modelo1, main = "Gradient Boosting Hyperparameters Tunning (Modelo 1)")
plot(gbm_modelo2, main = "Gradient Boosting Hyperparameters Tunning (Modelo 2)")
set.seed(1234)
gbmgrid<-expand.grid(shrinkage=c(0.4,0.3,0.2,0.1,0.05,0.03,0.01,0.001),
n.minobsinnode=c(5,10,20),
n.trees=c(100,500,1000,5000),
interaction.depth=c(2))
control<-trainControl(method = "cv",number=5,savePredictions = "all",
classProbs=TRUE)
gbm_modelo1 <- train(factor(target)~mortality_rsi+ccsMort30Rate+bmi+month.8+Age,data=surgical_dataset,
method="gbm",trControl=control,tuneGrid=gbmgrid,
distribution="bernoulli", bag.fraction=1,verbose=FALSE)
gbm_modelo1
plot(gbm_modelo1, main = "Gradient Boosting Hyperparameters Tunning (Modelo 1)")
# ------------- Gradient Boosting ---------------
# Objetivo: elaborar el mejor modelo de Gradient Boosting de acuerdo
#           a los valores de prediccion obtenidos tras variar los parametros
#           shrinkage, n.minobsnode, n.trees e interaction.depth
# Autor: Alberto Fernandez Hernandez
#--- Librerias
suppressPackageStartupMessages({
library(data.table)    # Lectura de ficheros mucho mas rapido que read.csv
library(parallel)      # Paralelizacion de funciones (I)
library(doParallel)    # Paralelizacion de funciones (II)
library(caret)         # Recursive Feature Elimination
library(randomForest)  # Seleccion del numero de arboles
library(readxl)        # Lectura de ficheros Excel
source("./librerias/librerias_propias.R")
})
#--- Creamos el cluster
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
#--- Lectura dataset depurado
surgical_dataset <- fread("./data/surgical_dataset_final.csv", data.table = FALSE)
surgical_dataset$target <- as.factor(surgical_dataset$target)
# Separamos variable objetivo del resto
target <- "target"
#--- Variables de los modelos candidatos
#--  Modelo 1
var_modelo1 <- c("mortality_rsi", "ccsMort30Rate", "bmi", "month.8", "Age")
#-- Modelo 2
var_modelo2 <- c("mortality_rsi", "bmi", "month.8", "Age")
#-- Prueba inicial Modelo 1
set.seed(1234)
gbmgrid<-expand.grid(shrinkage=c(0.4,0.3,0.2,0.1,0.05,0.03,0.01,0.001),
n.minobsinnode=c(5,10,20),
n.trees=c(100,500,1000,5000),
interaction.depth=c(2))
control<-trainControl(method = "cv",number=5,savePredictions = "all",
classProbs=TRUE)
gbm_modelo1 <- train(factor(target)~mortality_rsi+ccsMort30Rate+bmi+month.8+Age,data=surgical_dataset,
method="gbm",trControl=control,tuneGrid=gbmgrid,
distribution="bernoulli", bag.fraction=1,verbose=FALSE)
gbm_modelo1
plot(gbm_modelo1, main = "Gradient Boosting Hyperparameters Tunning (Modelo 1)")
gbm_modelo2 <- train(factor(target)~mortality_rsi+bmi+month.8+Age,data=surgical_dataset,
method="gbm",trControl=control,tuneGrid=gbmgrid,
distribution="bernoulli", bag.fraction=1,verbose=FALSE)
gbm_modelo2
plot(gbm_modelo2, main = "Gradient Boosting Hyperparameters Tunning (Modelo 2)")
plot(gbm_modelo1, main = "Gradient Boosting Hyperparameters Tunning (Modelo 1)")
set.seed(1234)
gbmgrid_aux<-expand.grid(shrinkage=c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7),
n.minobsinnode=c(10,20),
n.trees=c(100),
interaction.depth=c(2))
gbm_modelo1_aux <- train(factor(target)~mortality_rsi+ccsMort30Rate+bmi+month.8+Age,data=surgical_dataset,
method="gbm",trControl=control,tuneGrid=gbmgrid_aux,
distribution="bernoulli", bag.fraction=1,verbose=FALSE)
gbm_modelo1_aux
plot(gbm_modelo1_aux, main = "Gradient Boosting Hyperparameters Tunning (Modelo 1) aumentando shrinkage")
plot(gbm_modelo2, main = "Gradient Boosting Hyperparameters Tunning (Modelo 2)")
gbm_modelo2_aux <- train(factor(target)~mortality_rsi+bmi+month.8+Age,data=surgical_dataset,
method="gbm",trControl=control,tuneGrid=gbmgrid_aux,
distribution="bernoulli", bag.fraction=1,verbose=FALSE)
gbm_modelo2_aux
plot(gbm_modelo2_aux, main = "Gradient Boosting Hyperparameters Tunning (Modelo 2) aumentando shrinkage")
gbm_modelo2
set.seed(1234)
gbmgrid_early_stopping<-expand.grid(shrinkage=c(0.2),
n.minobsinnode=c(20),
n.trees=c(50, 100, 300, 500, 800, 1000, 1500, 2000, 2500, 5000),
interaction.depth=c(2))
gbm_modelo1_early_stopping <- train(factor(target)~mortality_rsi+ccsMort30Rate+bmi+month.8+Age,data=surgical_dataset,
method="gbm",trControl=control,tuneGrid=gbmgrid_early_stopping,
distribution="bernoulli", bag.fraction=1,verbose=FALSE)
gbm_modelo1_early_stopping
plot(gbm_modelo1_early_stopping, main = "Early Stopping (Modelo 1)")
gbmgrid_early_stopping_2<-expand.grid(shrinkage=c(0.3),
n.minobsinnode=c(20),
n.trees=c(50, 100, 300, 500, 800, 1000, 1500, 2000, 2500, 5000),
interaction.depth=c(2))
gbm_modelo1_early_stopping_2 <- train(factor(target)~mortality_rsi+ccsMort30Rate+bmi+month.8+Age,data=surgical_dataset,
method="gbm",trControl=control,tuneGrid=gbmgrid_early_stopping_2,
distribution="bernoulli", bag.fraction=1,verbose=FALSE)
lines(gbm_modelo1_early_stopping_2)
gbm_modelo1_early_stopping_2
gbm_modelo1_early_stopping_2$results
lines(gbm_modelo1_early_stopping_2$results$Accuracy)
plot(gbm_modelo1_early_stopping, main = "Early Stopping (Modelo 1)")
lines(gbm_modelo1_early_stopping_2$results$Accuracy)
lines(y = gbm_modelo1_early_stopping_2$results$Accuracy,
x = gbm_modelo1_early_stopping_2$results$n.trees)
plot(y = gbm_modelo1_early_stopping$results$Accuracy,
x = gbm_modelo1_early_stopping$results$n.trees, main = "Early Stopping (Modelo 1)")
plot(y = gbm_modelo1_early_stopping$results$Accuracy,
x = gbm_modelo1_early_stopping$results$n.trees, main = "Early Stopping (Modelo 1)", type = 'l')
plot(y = gbm_modelo1_early_stopping$results$Accuracy,
x = gbm_modelo1_early_stopping$results$n.trees, main = "Early Stopping (Modelo 1)", type = 'b')
lines(y = gbm_modelo1_early_stopping_2$results$Accuracy,
x = gbm_modelo1_early_stopping_2$results$n.trees)
lines(y = gbm_modelo1_early_stopping_2$results$Accuracy,
x = gbm_modelo1_early_stopping_2$results$n.trees, type = 'b')
plot(y = gbm_modelo1_early_stopping$results$Accuracy,
x = gbm_modelo1_early_stopping$results$n.trees, main = "Early Stopping (Modelo 1)", type = 'b')
lines(y = gbm_modelo1_early_stopping_2$results$Accuracy,
x = gbm_modelo1_early_stopping_2$results$n.trees, type = 'b')
plot(y = gbm_modelo1_early_stopping$results$Accuracy,
x = gbm_modelo1_early_stopping$results$n.trees, main = "Early Stopping (Modelo 1)", type = 'b',
col = 'red')
lines(y = gbm_modelo1_early_stopping_2$results$Accuracy,
x = gbm_modelo1_early_stopping_2$results$n.trees, type = 'b', col = 'blue')
gbm_modelo1_early_stopping$results %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees)) +
geom_point(color="#69b3a2") +
geom_text_repel(data=tmp_date) +
geom_segment(color="#69b3a2",
aes(
xend=c(tail(n.trees, n=-1), NA),
yend=c(tail(Accuracy, n=-1), NA)
),
arrow=arrow(length=unit(0.3,"cm"))
) +
theme_ipsum()
gbm_modelo1_early_stopping$results %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees)) +
geom_point(color="#69b3a2") +
geom_segment(color="#69b3a2",
aes(
xend=c(tail(n.trees, n=-1), NA),
yend=c(tail(Accuracy, n=-1), NA)
),
arrow=arrow(length=unit(0.3,"cm"))
) +
theme_ipsum()
install.packages("ggrepel")
library(ggrepel)
gbm_modelo1_early_stopping$results %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees)) +
geom_point(color="#69b3a2") +
geom_text_repel(data=tmp_date) +
geom_segment(color="#69b3a2",
aes(
xend=c(tail(n.trees, n=-1), NA),
yend=c(tail(Accuracy, n=-1), NA)
),
arrow=arrow(length=unit(0.3,"cm"))
) +
theme_ipsum()
gbm_modelo1_early_stopping$results %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees)) +
geom_point(color="#69b3a2") +
geom_text_repel(data=gbm_modelo1_early_stopping$results %>% sample_frac(0.3)) +
geom_segment(color="#69b3a2",
aes(
xend=c(tail(n.trees, n=-1), NA),
yend=c(tail(Accuracy, n=-1), NA)
),
arrow=arrow(length=unit(0.3,"cm"))
) +
theme_ipsum()
gbm_modelo1_early_stopping$results %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees)) +
geom_point(color="#69b3a2") +
geom_text_repel(data=gbm_modelo1_early_stopping$results %>% sample_frac(0.3)) +
geom_segment(color="#69b3a2",
aes(
xend=c(tail(n.trees, n=-1), NA),
yend=c(tail(Accuracy, n=-1), NA)
),
arrow=arrow(length=unit(0.3,"cm"))
)
gbm_modelo1_early_stopping$results %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees)) +
geom_point(color="#69b3a2") +
geom_text_repel(data=gbm_modelo1_early_stopping$results %>% sample_frac(0.3)) +
geom_segment(color="#69b3a2",
aes(
xend=c(tail(n.trees, n=-1), NA),
yend=c(tail(Accuracy, n=-1), NA)
))
gbm_modelo1_early_stopping$results %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees)) +
geom_point(color="#69b3a2") +
geom_text_repel(data=gbm_modelo1_early_stopping$results %>% sample_frac(0.5)) +
geom_segment(color="#69b3a2",
aes(
xend=c(tail(n.trees, n=-1), NA),
yend=c(tail(Accuracy, n=-1), NA)
))
gbm_modelo1_early_stopping$results %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees)) +
geom_point(color="#69b3a2") +
geom_text_repel(data=gbm_modelo1_early_stopping$results %>% sample_frac(0.8)) +
geom_segment(color="#69b3a2",
aes(
xend=c(tail(n.trees, n=-1), NA),
yend=c(tail(Accuracy, n=-1), NA)
)
)
gbm_modelo1_early_stopping$results %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees)) +
geom_point(color="#69b3a2") +
geom_text_repel(data=gbm_modelo1_early_stopping$results %>% sample_frac(1)) +
geom_segment(color="#69b3a2",
aes(
xend=c(tail(n.trees, n=-1), NA),
yend=c(tail(Accuracy, n=-1), NA)
)
)
gbm_modelo1_early_stopping$results %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees)) +
geom_point(color="#69b3a2") +
geom_text_repel(data=gbm_modelo1_early_stopping$results %>% sample_frac(0.6)) +
geom_segment(color="#69b3a2",
aes(
xend=c(tail(n.trees, n=-1), NA),
yend=c(tail(Accuracy, n=-1), NA)
)
)
gbm_modelo1_early_stopping$results %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees)) +
geom_point(color="#69b3a2") +
geom_text_repel(data=gbm_modelo1_early_stopping$results %>% sample_frac(0.6)) +
geom_segment(color="#69b3a2",
aes(
xend=c(tail(n.trees, n=-1), NA),
yend=c(tail(Accuracy, n=-1), NA)
)
) +
ggtitle("Evolucion Accuracy Modelo 1 (Early Stopping)")
gbm_modelo1_es_final <- rbind(gbm_modelo1_early_stopping, gbm_modelo1_early_stopping_2)
gbm_modelo1_es_final$shrinkage <- c(rep("0.2", 10), rep("0.3", 10))
gbm_modelo1_es_final$results %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees, col = shrinkage)) +
geom_point() +
geom_text_repel(data=gbm_modelo1_early_stopping$results %>% sample_frac(0.6)) +
geom_segment(aes(
xend=c(tail(n.trees, n=-1), NA),
yend=c(tail(Accuracy, n=-1), NA)
)
) +
ggtitle("Evolucion Accuracy Modelo 1 (Early Stopping)")
gbm_modelo1_es_final
gbm_modelo1_es_final <- rbind(gbm_modelo1_early_stopping$results, gbm_modelo1_early_stopping_2$results)
gbm_modelo1_es_final$shrinkage <- c(rep("0.2", 10), rep("0.3", 10))
gbm_modelo1_es_final$results %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees, col = shrinkage)) +
geom_point() +
geom_text_repel(data=gbm_modelo1_early_stopping$results %>% sample_frac(0.6)) +
geom_segment(aes(
xend=c(tail(n.trees, n=-1), NA),
yend=c(tail(Accuracy, n=-1), NA)
)
) +
ggtitle("Evolucion Accuracy Modelo 1 (Early Stopping)")
gbm_modelo1_es_final
gbm_modelo1_es_final %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees, col = shrinkage)) +
geom_point() +
geom_text_repel(data=gbm_modelo1_early_stopping$results %>% sample_frac(0.6)) +
geom_segment(aes(
xend=c(tail(n.trees, n=-1), NA),
yend=c(tail(Accuracy, n=-1), NA)
)
) +
ggtitle("Evolucion Accuracy Modelo 1 (Early Stopping)")
gbm_modelo1_es_final %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees,
group = shrinkage, col = shrinkage)) +
geom_point() +
geom_text_repel(data=gbm_modelo1_early_stopping$results %>% sample_frac(0.6)) +
geom_segment(aes(
xend=c(tail(n.trees, n=-1), NA),
yend=c(tail(Accuracy, n=-1), NA)
)
) +
ggtitle("Evolucion Accuracy Modelo 1 (Early Stopping)")
gbm_modelo1_es_final
gbm_modelo1_es_final %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees,
group = shrinkage, col = shrinkage)) +
geom_point() +
geom_text_repel(data=gbm_modelo1_es_final %>% sample_frac(0.6)) +
geom_segment(aes(
xend=c(tail(n.trees, n=-1), NA),
yend=c(tail(Accuracy, n=-1), NA)
)
) +
ggtitle("Evolucion Accuracy Modelo 1 (Early Stopping)")
gbm_modelo1_es_final %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees,
group = shrinkage, col = shrinkage)) +
geom_point() +
geom_text_repel(data=gbm_modelo1_es_final %>% sample_frac(0.6)) +
geom_segment(aes(
xend=c(tail(n.trees, n=1), NA),
yend=c(tail(Accuracy, n=1), NA)
)
) +
ggtitle("Evolucion Accuracy Modelo 1 (Early Stopping)")
gbm_modelo1_es_final %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees,
group = shrinkage, col = shrinkage)) +
geom_point() +
geom_text_repel(data=gbm_modelo1_es_final %>% sample_frac(0.6)) +
geom_segment(aes(
xend=c(tail(n.trees, n=20), NA),
yend=c(tail(Accuracy, n=20), NA)
)
) +
ggtitle("Evolucion Accuracy Modelo 1 (Early Stopping)")
gbm_modelo1_es_final %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees,
group = shrinkage, col = shrinkage)) +
geom_point() +
geom_text_repel(data=gbm_modelo1_es_final %>% sample_frac(0.6)) +
geom_segment(aes(
xend=c(tail(n.trees, n=1), NA),
yend=c(tail(Accuracy, n=1), NA)
)
) +
ggtitle("Evolucion Accuracy Modelo 1 (Early Stopping)")
gbm_modelo1_es_final %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees,
group = shrinkage, col = shrinkage)) +
geom_point() +
geom_text_repel(data=gbm_modelo1_es_final %>% sample_frac(0.6)) +
geom_segment(aes(
xend=c(tail(n.trees, n=-1), NA),
yend=c(tail(Accuracy, n=-1), NA)
)
) +
ggtitle("Evolucion Accuracy Modelo 1 (Early Stopping)")
gbm_modelo1_es_final %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees,
group = shrinkage, col = shrinkage)) +
geom_point() +
geom_text_repel(data=gbm_modelo1_es_final %>% sample_frac(0.7)) +
geom_segment(aes(
xend=c(tail(n.trees, n=-1), NA),
yend=c(tail(Accuracy, n=-1), NA)
)
) +
ggtitle("Evolucion Accuracy Modelo 1 (Early Stopping)")
gbm_modelo1_es_final %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees,
group = shrinkage, col = shrinkage)) +
geom_point() +
geom_text_repel(data=gbm_modelo1_es_final %>% sample_frac(0.7)) +
geom_segment() +
ggtitle("Evolucion Accuracy Modelo 1 (Early Stopping)")
gbm_modelo1_es_final %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees,
group = shrinkage, col = shrinkage)) +
geom_point() +
geom_text_repel(data=gbm_modelo1_es_final %>% sample_frac(0.7)) +
ggtitle("Evolucion Accuracy Modelo 1 (Early Stopping)")
gbm_modelo1_es_final %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees,
group = shrinkage, col = shrinkage)) +
geom_point() +
geom_smooth() +
geom_text_repel(data=gbm_modelo1_es_final %>% sample_frac(0.7)) +
ggtitle("Evolucion Accuracy Modelo 1 (Early Stopping)")
gbm_modelo1_es_final %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees,
group = shrinkage, col = shrinkage)) +
geom_point() +
geom_line() +
geom_text_repel(data=gbm_modelo1_es_final %>% sample_frac(0.7)) +
ggtitle("Evolucion Accuracy Modelo 1 (Early Stopping)")
gbm_modelo1_es_final %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees,
group = shrinkage, col = shrinkage)) +
geom_point() +
geom_line() +
geom_text_repel(data=gbm_modelo1_es_final %>% sample_frac(0.5)) +
ggtitle("Evolucion Accuracy Modelo 1 (Early Stopping)")
gbm_modelo1_es_final %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees,
group = shrinkage, col = shrinkage)) +
geom_point() +
geom_line() +
geom_text_repel(data=gbm_modelo1_es_final %>% sample_frac(0.6)) +
ggtitle("Evolucion Accuracy Modelo 1 (Early Stopping)")
gbm_modelo2_early_stopping <- train(factor(target)~mortality_rsi+bmi+month.8+Age,data=surgical_dataset,
method="gbm",trControl=control,tuneGrid=gbmgrid_early_stopping,
distribution="bernoulli", bag.fraction=1,verbose=FALSE)
gbm_modelo2_early_stopping_2 <- train(factor(target)~mortality_rsi+bmi+month.8+Age,data=surgical_dataset,
method="gbm",trControl=control,tuneGrid=gbmgrid_early_stopping_2,
distribution="bernoulli", bag.fraction=1,verbose=FALSE)
gbm_modelo2_es_final <- rbind(gbm_modelo1_early_stopping$results, gbm_modelo2_early_stopping_2$results)
gbm_modelo2_es_final$shrinkage <- c(rep("0.2", 10), rep("0.3", 10))
gbm_modelo2_es_final %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees,
group = shrinkage, col = shrinkage)) +
geom_point() +
geom_line() +
geom_text_repel(data=gbm_modelo1_es_final %>% sample_frac(0.6)) +
ggtitle("Evolucion Accuracy Modelo 2 (Early Stopping)")
gbm_modelo2_es_final %>% ggplot(aes(x = n.trees, y = Accuracy, label = n.trees,
group = shrinkage, col = shrinkage)) +
geom_point() +
geom_line() +
geom_text_repel(data=gbm_modelo2_es_final %>% sample_frac(0.6)) +
ggtitle("Evolucion Accuracy Modelo 2 (Early Stopping)")
save.image("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/GradientBoosting.RData")
