print(punto_corte)
}
resultadosxgboost<-function(dataf=dataf,vardep=vardep,listconti,
min_child_weight=20,eta=0.1,nrounds=100,max_depth=6,
gamma=0,colsample_bytree=1,subsample=1,alpha=0,lambda=0,lambda_bias=0,
corte=0.5)
{
library(caret)
library(pROC)
tasafallos<-function(x,y) {
confu<-confusionMatrix(x,y)
tasa<-confu[[3]][1]
return(tasa)
}
auc<-function(x,y) {
curvaroc<-roc(response=x,predictor=y)
auc<-curvaroc$auca
return(auc)
}
set.seed(1234)
control<-trainControl(method = "cv",number=5,savePredictions = "all",classProbs=TRUE)
# PREPARACIÓN DATOS
tabla1<-as.data.frame(table(dataf[,vardep]))
tabla1<-tabla1[order(tabla1$Freq),]
minoritaria<-as.character(tabla1[1,c("Var1")])
tabla1<-tabla1[order(-tabla1$Freq),]
mayoritaria<-as.character(tabla1[1,c("Var1")])
if (minoritaria==mayoritaria)
{
tabla1<-tabla1[order(tabla1$Freq),]
mayoritaria<-as.character(tabla1[2,c("Var1")])
}
cosa<-as.data.frame(prop.table(table(dataf[[vardep]])))
fremin<-100*round(min(cosa$Freq),2)
totalobs=nrow(dataf)
cosa<-as.data.frame(table(dataf[[vardep]]))
totalmin<-round(min(cosa$Freq),2)
dataf[vardep]<-ifelse(dataf[vardep]==minoritaria,"Yes","No")
formu1<-paste("factor(",target,")~",paste0(listconti, collapse = "+"))
xgbmgrid <-expand.grid( min_child_weight=min_child_weight,
eta=eta,nrounds=nrounds,max_depth=max_depth,
gamma=gamma,colsample_bytree=colsample_bytree,subsample=subsample)
print(formu1)
gbm <- train(formu1,data=dataf,
method="xgbTree",trControl=control,
tuneGrid=xgbmgrid,verbose=FALSE,
alpha=alpha,lambda=lambda,lambda_bias=lambda_bias)
preditest<-gbm$pred
preditest$pred<-ifelse(preditest$Yes>corte,"Yes","No")
preditest$pred<-as.factor(preditest$pred)
tasa=1-tasafallos(preditest$pred,preditest$obs)
auc=auc(preditest$obs,preditest$Yes)
a<-as.data.frame(table(preditest$pred))
nYes<-a[2,2]
if (is.na(nYes)==T)
{nYes=0}
confu<-confusionMatrix(preditest$pred,preditest$obs)
FP<-confu[[2]][2]
FN<-confu[[2]][3]
VP<-confu[[2]][4]
VN<-confu[[2]][1]
print("HOLA")
sensitivity <- as.numeric(sensitivity(preditest$pred,preditest$obs,"Yes"))
especificity <- as.numeric(specificity(preditest$pred,preditest$obs,"No"))
return(list("FP" = FP,"FN" = FN,"VP" = VP,
"VN" = VN,"AUC" = auc,"tasa" = tasa,
"sensitividad" = as.numeric(sensitivity),
"especificidad" = as.numeric(especificity)))
}
# EJEMPLO
# v<-toydata(n=400,0.4,1,1,5,-5,0.0000)
# v[[1]]+theme(legend.position = "none")+xlab("")+ylab("")
# dataf<-v[[2]]
# vardep<-"clase"
# res<-resultadosgbm(dataf=dataf,vardep=vardep)
for(punto_corte in puntos_corte) {
result_xgboost <- resultadosxgboost(dataf=surgical_dataset,
vardep=target,listconti=var_modelo2,
corte=punto_corte)
result_xgboost$AUC <- as.numeric(result_xgboost$AUC)
result_xgboost$tasa <- as.numeric(result_xgboost$tasa)
result_xgboost$pto_corte <- punto_corte
dataframe_puntos_corte_xgboost <- rbind(dataframe_puntos_corte_xgboost, result_xgboost)
print(punto_corte)
}
View(cruzadaxgbmbin)
View(cruzadarfbin)
save.image("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/PuntoDeCorte.RData")
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/RandomForest.RData")
library(dummies)
library(MASS)
library(reshape)
library(caret)
library(pROC)
cruzadarfbin<-
function(data=data,vardep="vardep",
listconti="listconti",listclass="listclass",
grupos=4,sinicio=1234,repe=5,nodesize=20,
mtry=2,ntree=50,replace=TRUE,sampsize=1, show_nrnodes = "no")
{
# if  (sampsize==1)
# {
#  sampsize=floor(nrow(data)/(grupos-1))
# }
# Preparación del archivo
# b)pasar las categóricas a dummies
if (any(listclass==c(""))==FALSE)
{
databis<-data[,c(vardep,listconti,listclass)]
databis<- dummy.data.frame(databis, listclass, sep = ".")
}  else   {
databis<-data[,c(vardep,listconti)]
}
# c)estandarizar las variables continuas
# Calculo medias y dtipica de datos y estandarizo (solo las continuas)
means <-apply(databis[,listconti],2,mean)
sds<-sapply(databis[,listconti],sd)
# Estandarizo solo las continuas y uno con las categoricas
datacon<-scale(databis[,listconti], center = means, scale = sds)
numerocont<-which(colnames(databis)%in%listconti)
databis<-cbind(datacon,databis[,-numerocont,drop=FALSE ])
databis[,vardep]<-as.factor(databis[,vardep])
print(names(databis))
formu<-formula(paste("factor(",vardep,")~.",sep=""))
# Preparo caret
set.seed(sinicio)
control<-trainControl(method = "repeatedcv",number=grupos,repeats=repe,
savePredictions = "all",classProbs=TRUE)
# Aplico caret y construyo modelo
rfgrid <-expand.grid(mtry=mtry)
if  (sampsize==1)
{
rf<- train(formu,data=databis,
method="rf",trControl=control,
tuneGrid=rfgrid,nodesize=nodesize,replace=replace,ntree=ntree)
}
else  if  (sampsize!=1)
{
rf<- train(formu,data=databis,
method="rf",trControl=control,
tuneGrid=rfgrid,nodesize=nodesize,replace=replace,sampsize=sampsize,
ntree=ntree)
}
if(show_nrnodes == "yes") {
print(rf$finalModel$forest$nrnodes)
print("--------------")
}
print(rf$results)
preditest<-rf$pred
preditest$prueba<-strsplit(preditest$Resample,"[.]")
preditest$Fold <- sapply(preditest$prueba, "[", 1)
preditest$Rep <- sapply(preditest$prueba, "[", 2)
preditest$prueba<-NULL
tasafallos<-function(x,y) {
confu<-confusionMatrix(x,y)
tasa<-confu[[3]][1]
return(tasa)
}
# Aplicamos función sobre cada Repetición
tabla<-table(preditest$Rep)
listarep<-c(names(tabla))
medias<-data.frame()
for (repi in listarep) {
paso1<-preditest[which(preditest$Rep==repi),]
tasa=1-tasafallos(paso1$pred,paso1$obs)
medias<-rbind(medias,tasa)
}
names(medias)<-"tasa"
# CalculamoS AUC  por cada Repetición de cv
# Definimnos función
auc<-function(x,y) {
curvaroc<-roc(response=x,predictor=y)
auc<-curvaroc$auc
return(auc)
}
# Aplicamos función sobre cada Repetición
mediasbis<-data.frame()
for (repi in listarep) {
paso1<-preditest[which(preditest$Rep==repi),]
auc=suppressMessages(auc(paso1$obs,paso1$Yes))
mediasbis<-rbind(mediasbis,auc)
}
names(mediasbis)<-"auc"
# Unimos la info de auc y de tasafallos
medias$auc<-mediasbis$auc
return(medias)
}
#
#
# load ("saheartbis.Rda")
# source ("cruzadas avnnet y log binaria.R")
# source ("cruzada arbolbin.R")
#
# medias1<-cruzadalogistica(data=saheartbis,
#  vardep="chd",listconti=c("sbp", "tobacco", "ldl",
#   "adiposity",  "obesity", "famhist.Absent"),
#  listclass=c(""), grupos=4,sinicio=1234,repe=5)
#
#  medias1$modelo="Logística"
#
#
# medias2<-cruzadaavnnetbin(data=saheartbis,
#  vardep="chd",listconti=c("sbp", "tobacco",
#   "ldl", "adiposity",  "obesity", "famhist.Absent"),
#  listclass=c(""),grupos=4,sinicio=1234,repe=5,
#   size=c(5),decay=c(0.1),repeticiones=5,itera=200)
#
#   medias2$modelo="avnnet"
#
#
#   medias3<-cruzadaarbolbin(data=saheartbis,
#  vardep="chd",listconti=c("sbp", "tobacco",
#   "ldl", "adiposity",  "obesity", "famhist.Absent"),
#  listclass=c(""),grupos=4,sinicio=1234,repe=5,
#   cp=c(0),minbucket =5)
#
#   medias3$modelo="arbol"
#
#
#  medias4<-cruzadarfbin(data=saheartbis, vardep="chd",
#   listconti=c("sbp", "tobacco",
#  "ldl", "adiposity",  "obesity", "famhist.Absent"),
# listclass=c(""),
#  grupos=4,sinicio=1234,repe=5,nodesize=10,
#  mtry=6,ntree=200,replace=TRUE)
#
#  medias4$modelo="bagging"
#
#
# union1<-rbind(medias1,medias2,medias3,medias4)
#
# par(cex.axis=0.5)
# boxplot(data=union1,tasa~modelo,main="TASA FALLOS")
# boxplot(data=union1,auc~modelo,main="AUC")
cruzadarfbin(data=surgical_dataset, vardep=target,listconti=var_modelo1,listclass=c(""),
grupos=5,sinicio=1234,repe=5,nodesize=10,mtry=mtry.1,ntree=2500,replace=TRUE)
resultadosxgboost<-function(dataf=dataf,vardep=vardep,listconti,
min_child_weight=20,eta=0.1,nrounds=100,max_depth=6,
gamma=0,colsample_bytree=1,subsample=1,alpha=0,lambda=0,lambda_bias=0,
corte=0.5)
{
library(caret)
library(pROC)
tasafallos<-function(x,y) {
confu<-confusionMatrix(x,y)
tasa<-confu[[3]][1]
return(tasa)
}
auc<-function(x,y) {
curvaroc<-roc(response=x,predictor=y)
auc<-curvaroc$auca
return(auc)
}
set.seed(1234)
control<-trainControl(method = "cv",number=5,savePredictions = "all",classProbs=TRUE)
# PREPARACIÓN DATOS
tabla1<-as.data.frame(table(dataf[,vardep]))
tabla1<-tabla1[order(tabla1$Freq),]
minoritaria<-as.character(tabla1[1,c("Var1")])
tabla1<-tabla1[order(-tabla1$Freq),]
mayoritaria<-as.character(tabla1[1,c("Var1")])
if (minoritaria==mayoritaria)
{
tabla1<-tabla1[order(tabla1$Freq),]
mayoritaria<-as.character(tabla1[2,c("Var1")])
}
cosa<-as.data.frame(prop.table(table(dataf[[vardep]])))
fremin<-100*round(min(cosa$Freq),2)
totalobs=nrow(dataf)
cosa<-as.data.frame(table(dataf[[vardep]]))
totalmin<-round(min(cosa$Freq),2)
dataf[vardep]<-ifelse(dataf[vardep]==minoritaria,"Yes","No")
formu1<-paste("factor(",target,")~",paste0(listconti, collapse = "+"))
xgbmgrid <-expand.grid( min_child_weight=min_child_weight,
eta=eta,nrounds=nrounds,max_depth=max_depth,
gamma=gamma,colsample_bytree=colsample_bytree,subsample=subsample)
gbm <- train(formu1,data=dataf,
method="xgbTree",trControl=control,
tuneGrid=xgbmgrid,verbose=FALSE,
alpha=alpha,lambda=lambda,lambda_bias=lambda_bias)
print("HOLA")
preditest<-gbm$pred
preditest$pred<-ifelse(preditest$Yes>corte,"Yes","No")
preditest$pred<-as.factor(preditest$pred)
tasa=1-tasafallos(preditest$pred,preditest$obs)
auc=auc(preditest$obs,preditest$Yes)
a<-as.data.frame(table(preditest$pred))
nYes<-a[2,2]
if (is.na(nYes)==T)
{nYes=0}
confu<-confusionMatrix(preditest$pred,preditest$obs)
FP<-confu[[2]][2]
FN<-confu[[2]][3]
VP<-confu[[2]][4]
VN<-confu[[2]][1]
print("HOLA")
sensitivity <- as.numeric(sensitivity(preditest$pred,preditest$obs,"Yes"))
especificity <- as.numeric(specificity(preditest$pred,preditest$obs,"No"))
return(list("FP" = FP,"FN" = FN,"VP" = VP,
"VN" = VN,"AUC" = auc,"tasa" = tasa,
"sensitividad" = as.numeric(sensitivity),
"especificidad" = as.numeric(especificity)))
}
# EJEMPLO
# v<-toydata(n=400,0.4,1,1,5,-5,0.0000)
# v[[1]]+theme(legend.position = "none")+xlab("")+ylab("")
# dataf<-v[[2]]
# vardep<-"clase"
# res<-resultadosgbm(dataf=dataf,vardep=vardep)
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/PuntoDeCorte.RData")
resultadosxgboost<-function(dataf=dataf,vardep=vardep,listconti,
min_child_weight=20,eta=0.1,nrounds=100,max_depth=6,
gamma=0,colsample_bytree=1,subsample=1,alpha=0,lambda=0,lambda_bias=0,
corte=0.5)
{
library(caret)
library(pROC)
tasafallos<-function(x,y) {
confu<-confusionMatrix(x,y)
tasa<-confu[[3]][1]
return(tasa)
}
auc<-function(x,y) {
curvaroc<-roc(response=x,predictor=y)
auc<-curvaroc$auca
return(auc)
}
set.seed(1234)
control<-trainControl(method = "cv",number=5,savePredictions = "all",classProbs=TRUE)
# PREPARACIÓN DATOS
tabla1<-as.data.frame(table(dataf[,vardep]))
tabla1<-tabla1[order(tabla1$Freq),]
minoritaria<-as.character(tabla1[1,c("Var1")])
tabla1<-tabla1[order(-tabla1$Freq),]
mayoritaria<-as.character(tabla1[1,c("Var1")])
if (minoritaria==mayoritaria)
{
tabla1<-tabla1[order(tabla1$Freq),]
mayoritaria<-as.character(tabla1[2,c("Var1")])
}
cosa<-as.data.frame(prop.table(table(dataf[[vardep]])))
fremin<-100*round(min(cosa$Freq),2)
totalobs=nrow(dataf)
cosa<-as.data.frame(table(dataf[[vardep]]))
totalmin<-round(min(cosa$Freq),2)
dataf[vardep]<-ifelse(dataf[vardep]==minoritaria,"Yes","No")
formu1<-paste("factor(",target,")~",paste0(listconti, collapse = "+"))
xgbmgrid <-expand.grid( min_child_weight=min_child_weight,
eta=eta,nrounds=nrounds,max_depth=max_depth,
gamma=gamma,colsample_bytree=colsample_bytree,subsample=subsample)
gbm <- train(formu1,data=dataf,
method="xgbTree",trControl=control,
tuneGrid=xgbmgrid,verbose=FALSE,
alpha=alpha,lambda=lambda,lambda_bias=lambda_bias)
print("HOLA")
preditest<-gbm$pred
preditest$pred<-ifelse(preditest$Yes>corte,"Yes","No")
preditest$pred<-as.factor(preditest$pred)
tasa=1-tasafallos(preditest$pred,preditest$obs)
auc=auc(preditest$obs,preditest$Yes)
a<-as.data.frame(table(preditest$pred))
nYes<-a[2,2]
if (is.na(nYes)==T)
{nYes=0}
confu<-confusionMatrix(preditest$pred,preditest$obs)
FP<-confu[[2]][2]
FN<-confu[[2]][3]
VP<-confu[[2]][4]
VN<-confu[[2]][1]
print("HOLA")
sensitivity <- as.numeric(sensitivity(preditest$pred,preditest$obs,"Yes"))
especificity <- as.numeric(specificity(preditest$pred,preditest$obs,"No"))
return(list("FP" = FP,"FN" = FN,"VP" = VP,
"VN" = VN,"AUC" = auc,"tasa" = tasa,
"sensitividad" = as.numeric(sensitivity),
"especificidad" = as.numeric(especificity)))
}
# EJEMPLO
# v<-toydata(n=400,0.4,1,1,5,-5,0.0000)
# v[[1]]+theme(legend.position = "none")+xlab("")+ylab("")
# dataf<-v[[2]]
# vardep<-"clase"
# res<-resultadosgbm(dataf=dataf,vardep=vardep)
for(punto_corte in puntos_corte) {
result_xgboost <- resultadosxgboost(dataf=surgical_dataset,
vardep=target,listconti=var_modelo2,
corte=punto_corte)
result_xgboost$AUC <- as.numeric(result_xgboost$AUC)
result_xgboost$tasa <- as.numeric(result_xgboost$tasa)
result_xgboost$pto_corte <- punto_corte
dataframe_puntos_corte_xgboost <- rbind(dataframe_puntos_corte_xgboost, result_xgboost)
print(punto_corte)
}
resultadosxgboost<-function(dataf=dataf,vardep=vardep,listconti,
min_child_weight=20,eta=0.1,nrounds=100,max_depth=6,
gamma=0,colsample_bytree=1,subsample=1,alpha=0,lambda=0,lambda_bias=0,
corte=0.5)
{
library(caret)
library(pROC)
tasafallos<-function(x,y) {
confu<-confusionMatrix(x,y)
tasa<-confu[[3]][1]
return(tasa)
}
auc<-function(x,y) {
curvaroc<-roc(response=x,predictor=y)
auc<-curvaroc$auca
return(auc)
}
set.seed(1234)
control<-trainControl(method = "cv",number=5,savePredictions = "all",classProbs=TRUE)
# PREPARACIÓN DATOS
tabla1<-as.data.frame(table(dataf[,vardep]))
tabla1<-tabla1[order(tabla1$Freq),]
minoritaria<-as.character(tabla1[1,c("Var1")])
tabla1<-tabla1[order(-tabla1$Freq),]
mayoritaria<-as.character(tabla1[1,c("Var1")])
if (minoritaria==mayoritaria)
{
tabla1<-tabla1[order(tabla1$Freq),]
mayoritaria<-as.character(tabla1[2,c("Var1")])
}
cosa<-as.data.frame(prop.table(table(dataf[[vardep]])))
fremin<-100*round(min(cosa$Freq),2)
totalobs=nrow(dataf)
cosa<-as.data.frame(table(dataf[[vardep]]))
totalmin<-round(min(cosa$Freq),2)
dataf[vardep]<-ifelse(dataf[vardep]==minoritaria,"Yes","No")
formu1<-as.formula(paste("factor(",target,")~",paste0(listconti, collapse = "+")))
xgbmgrid <-expand.grid( min_child_weight=min_child_weight,
eta=eta,nrounds=nrounds,max_depth=max_depth,
gamma=gamma,colsample_bytree=colsample_bytree,subsample=subsample)
gbm <- train(formu1,data=dataf,
method="xgbTree",trControl=control,
tuneGrid=xgbmgrid,verbose=FALSE,
alpha=alpha,lambda=lambda,lambda_bias=lambda_bias)
print("HOLA")
preditest<-gbm$pred
preditest$pred<-ifelse(preditest$Yes>corte,"Yes","No")
preditest$pred<-as.factor(preditest$pred)
tasa=1-tasafallos(preditest$pred,preditest$obs)
auc=auc(preditest$obs,preditest$Yes)
a<-as.data.frame(table(preditest$pred))
nYes<-a[2,2]
if (is.na(nYes)==T)
{nYes=0}
confu<-confusionMatrix(preditest$pred,preditest$obs)
FP<-confu[[2]][2]
FN<-confu[[2]][3]
VP<-confu[[2]][4]
VN<-confu[[2]][1]
print("HOLA")
sensitivity <- as.numeric(sensitivity(preditest$pred,preditest$obs,"Yes"))
especificity <- as.numeric(specificity(preditest$pred,preditest$obs,"No"))
return(list("FP" = FP,"FN" = FN,"VP" = VP,
"VN" = VN,"AUC" = auc,"tasa" = tasa,
"sensitividad" = as.numeric(sensitivity),
"especificidad" = as.numeric(especificity)))
}
# EJEMPLO
# v<-toydata(n=400,0.4,1,1,5,-5,0.0000)
# v[[1]]+theme(legend.position = "none")+xlab("")+ylab("")
# dataf<-v[[2]]
# vardep<-"clase"
# res<-resultadosgbm(dataf=dataf,vardep=vardep)
for(punto_corte in puntos_corte) {
result_xgboost <- resultadosxgboost(dataf=surgical_dataset,
vardep=target,listconti=var_modelo2,
corte=punto_corte)
result_xgboost$AUC <- as.numeric(result_xgboost$AUC)
result_xgboost$tasa <- as.numeric(result_xgboost$tasa)
result_xgboost$pto_corte <- punto_corte
dataframe_puntos_corte_xgboost <- rbind(dataframe_puntos_corte_xgboost, result_xgboost)
print(punto_corte)
}
dataframe_puntos_corte_xgboost <- data.frame()
for(punto_corte in puntos_corte) {
result_xgboost <- resultadosxgboost(dataf=surgical_dataset,
vardep=target,listconti=var_modelo2,
corte=punto_corte)
result_xgboost$AUC <- as.numeric(result_xgboost$AUC)
result_xgboost$tasa <- as.numeric(result_xgboost$tasa)
result_xgboost$pto_corte <- punto_corte
dataframe_puntos_corte_xgboost <- rbind(dataframe_puntos_corte_xgboost, result_xgboost)
print(punto_corte)
}
dataframe_puntos_corte_xgboost
result_xgboost
result_xgboost$AUC <- as.numeric(result_xgboost$AUC)
result_xgboost$tasa <- as.numeric(result_xgboost$tasa)
result_xgboost$pto_corte <- punto_corte
rbind(dataframe_puntos_corte_xgboost, result_xgboost)
rbind(dataframe_puntos_corte_xgboost, result_xgboost)
result_xgboost$AUC
result_xgboost <- resultadosxgboost(dataf=surgical_dataset,
vardep=target,listconti=var_modelo2,
corte=punto_corte)
result_xgboost$AUC
for(punto_corte in puntos_corte) {
result_xgboost <- resultadosxgboost(dataf=surgical_dataset,
vardep=target,listconti=var_modelo2,
corte=punto_corte)
result_xgboost$AUC <- ifelse(is.null(result_xgboost$AUC), 0, as.numeric(result_xgboost$AUC))
result_xgboost$tasa <- as.numeric(result_xgboost$tasa)
result_xgboost$pto_corte <- punto_corte
dataframe_puntos_corte_xgboost <- rbind(dataframe_puntos_corte_xgboost, result_xgboost)
print(punto_corte)
}
dataframe_puntos_corte_xgboost
dataframe_puntos_corte_gbm
save.image("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/PuntoDeCorte.RData")
