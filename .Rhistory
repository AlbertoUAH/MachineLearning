# ------------- Gradient Boosting ---------------
# Objetivo: elaborar el mejor modelo de Gradient Boosting de acuerdo
#           a los valores de prediccion obtenidos tras variar los parametros
#           shrinkage, n.minobsnode, n.trees e interaction.depth
# Autor: Alberto Fernandez Hernandez
#--- Librerias
suppressPackageStartupMessages({
library(data.table)    # Lectura de ficheros mucho mas rapido que read.csv
library(parallel)      # Paralelizacion de funciones (I)
library(doParallel)    # Paralelizacion de funciones (II)
library(caret)         # Recursive Feature Elimination
library(randomForest)  # Seleccion del numero de arboles
library(readxl)        # Lectura de ficheros Excel
library(ggrepel)       # Evita solapamientos en las etiquetas de un grafico
source("./librerias/librerias_propias.R")
})
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
#--- Lectura dataset depurado
surgical_dataset <- fread("./data/surgical_dataset_final.csv", data.table = FALSE)
surgical_dataset$target <- as.factor(surgical_dataset$target)
# Separamos variable objetivo del resto
target <- "target"
#--- Variables de los modelos candidatos
#--  Modelo 1
var_modelo1 <- c("mortality_rsi", "ccsMort30Rate", "bmi", "month.8", "Age")
#-- Modelo 2
var_modelo2 <- c("mortality_rsi", "bmi", "month.8", "Age")
graph
graph_2 <- ggplot(gbm_modelo2_early_stopping_bag_fraction, aes(x = n.trees, y = Accuracy, colour = bag.fraction)) +
geom_point() +
facet_grid( . ~ shrinkage )+
facet_wrap(. ~ shrinkage, ncol = 2, scales = "free_x")
labs(colour = 'bag.fraction') +
theme_grey() +
theme(
legend.position = 'right'
)
graph_2
graph <- ggplot(gbm_modelo1_early_stopping_bag_fraction, aes(x = n.trees, y = Accuracy, color = bag.fraction)) +
geom_point() +
facet_grid( . ~ shrinkage )+
facet_wrap(. ~ shrinkage, ncol = 2, scales = "free_x")
labs(colour = 'bag.fraction') +
theme_grey() +
theme(
legend.position = 'right'
)
graph
graph <- ggplot(gbm_modelo1_early_stopping_bag_fraction, aes(x = n.trees, y = Accuracy, color = bag.fraction)) +
geom_point() +
scale_color_identity() +
facet_grid( . ~ shrinkage )+
facet_wrap(. ~ shrinkage, ncol = 2, scales = "free_x")
labs(colour = 'bag.fraction') +
theme_grey() +
theme(
legend.position = 'right'
)
graph
graph <- ggplot(gbm_modelo1_early_stopping_bag_fraction, aes(x = n.trees, y = Accuracy, colour = bag.fraction)) +
geom_point() +
labs(colour = 'bag.fraction') +
theme_grey() +
theme(
legend.position = 'right'
)
graph
library(RColorBrewer)  # Paleta de colores
gbm_modelo1_early_stopping_bag_fraction
colores <- brewer.pal(7,"Set1")
levels(gbm_modelo1_early_stopping_bag_fraction$bag.fraction)
unique(gbm_modelo1_early_stopping_bag_fraction$bag.fraction)
names(colores) <- unique(gbm_modelo1_early_stopping_bag_fraction$bag.fraction)
colScale <- scale_colour_manual(name = "grp",values = colores)
colScale
graph <- ggplot(gbm_modelo1_early_stopping_bag_fraction, aes(x = n.trees, y = Accuracy, colour = bag.fraction)) +
geom_point() +
colScale +
facet_grid( . ~ shrinkage )+
facet_wrap(. ~ shrinkage, ncol = 2, scales = "free_x")
labs(colour = 'bag.fraction') +
theme_grey() +
theme(
legend.position = 'right'
)
graph
colores <- brewer.pal(7,"Set1")
names(colores) <- as.factor(unique(gbm_modelo1_early_stopping_bag_fraction$bag.fraction))
colScale <- scale_colour_manual(name = "grp",values = colores)
graph <- ggplot(gbm_modelo1_early_stopping_bag_fraction, aes(x = n.trees, y = Accuracy, colour = bag.fraction)) +
geom_point() +
colScale +
facet_grid( . ~ shrinkage )+
facet_wrap(. ~ shrinkage, ncol = 2, scales = "free_x")
labs(colour = 'bag.fraction') +
theme_grey() +
theme(
legend.position = 'right'
)
graph
colScale
graph <- ggplot(gbm_modelo1_early_stopping_bag_fraction, aes(x = n.trees, y = Accuracy, colour = bag.fraction)) +
geom_point() +
colScale +
facet_grid( . ~ shrinkage )+
facet_wrap(. ~ shrinkage, ncol = 2)
labs(colour = 'bag.fraction') +
theme_grey() +
theme(
legend.position = 'right'
)
graph
graph <- ggplot(gbm_modelo1_early_stopping_bag_fraction, aes(x = n.trees, y = Accuracy, colour = bag.fraction)) +
geom_point() +
facet_grid( . ~ shrinkage )+
facet_wrap(. ~ shrinkage, ncol = 2)
labs(colour = 'bag.fraction') +
theme_grey() +
theme(
legend.position = 'right'
)
graph
#-- Analicemos el modelo 1
gbm_modelo1_early_stopping_bag_fraction$bag.fraction <- as.factor(gbm_modelo1_early_stopping_bag_fraction$bag.fraction)
graph <- ggplot(gbm_modelo1_early_stopping_bag_fraction, aes(x = n.trees, y = Accuracy, colour = bag.fraction)) +
geom_point() +
facet_grid( . ~ shrinkage )+
facet_wrap(. ~ shrinkage, ncol = 2, scales = "free_x")
labs(colour = 'bag.fraction') +
theme_grey() +
theme(
legend.position = 'right'
)
graph
gbm_modelo2_early_stopping_bag_fraction$bag.fraction <- as.factor(gbm_modelo2_early_stopping_bag_fraction$bag.fraction)
graph_2 <- ggplot(gbm_modelo2_early_stopping_bag_fraction, aes(x = n.trees, y = Accuracy, color = bag.fraction)) +
geom_point() +
facet_grid( . ~ shrinkage )+
facet_wrap(. ~ shrinkage, ncol = 2, scales = "free_x")
labs(colour = 'bag.fraction') +
theme_grey() +
theme(
legend.position = 'right'
)
graph_2
5854*0.8
5854*0.5
tuneo_gradient_boosting_modelo1 <- tuneo_gradient_boosting(
dataset = surgical_dataset, lista.continua = var_modelo1, target = target,
n.trees = 100, n.minobsinnode = 20, bag.fraction = c(0.5, 1), shrinkage = c(0.3),
interaction.depth = 2, grupos = 5, repe = 10, path.1 = "",
path.2 = ""
)
var_modelo2
tuneo_gradient_boosting_modelo2 <- tuneo_gradient_boosting(
dataset = surgical_dataset, lista.continua = var_modelo2, target = target,
n.trees = 100, n.minobsinnode = 20, bag.fraction = c(0.5, 1), shrinkage = c(0.3),
interaction.depth = 2, grupos = 5, repe = 10, path.1 = "",
path.2 = ""
)
gbm_modelo1_early_stopping_bag_fraction
tuneo_gradient_boosting_modelo1 <- tuneo_gradient_boosting(
dataset = surgical_dataset, lista.continua = var_modelo1, target = target,
n.trees = 100, n.minobsinnode = 20, bag.fraction = c(0.5, 1), shrinkage = c(0.3),
interaction.depth = 2, grupos = 5, repe = 5, path.1 = "",
path.2 = ""
)
tuneo_gradient_boosting_modelo1_10rep <- tuneo_gradient_boosting(
dataset = surgical_dataset, lista.continua = var_modelo1, target = target,
n.trees = 100, n.minobsinnode = 20, bag.fraction = c(0.5, 1), shrinkage = c(0.3),
interaction.depth = 2, grupos = 5, repe = 10, path.1 = "",
path.2 = ""
)
tuneo_gradient_boosting_modelo2 <- tuneo_gradient_boosting(
dataset = surgical_dataset, lista.continua = var_modelo2, target = target,
n.trees = 100, n.minobsinnode = 20, bag.fraction = c(0.5, 1), shrinkage = c(0.3),
interaction.depth = 2, grupos = 5, repe = 5, path.1 = "",
path.2 = ""
)
tuneo_gradient_boosting_modelo2_10_rep <- tuneo_gradient_boosting(
dataset = surgical_dataset, lista.continua = var_modelo2, target = target,
n.trees = 100, n.minobsinnode = 20, bag.fraction = c(0.5, 1), shrinkage = c(0.3),
interaction.depth = 2, grupos = 5, repe = 10, path.1 = "",
path.2 = ""
)
tuneo_gradient_boosting_modelo2
tuneo_gradient_boosting_modelo1
tuneo_gradient_boosting_modelo1_10rep
tuneo_modelo1 <- rbind(tuneo_gradient_boosting_modelo1, tuneo_gradient_boosting_modelo1_10rep)
tuneo_modelo1$rep <- c(rep("5", 30), rep("10", 60))
c(rep("5", 30), rep("10", 60))
tuneo_modelo1
tuneo_modelo1$rep <- c(rep("5", 10), rep("10", 20))
tuneo_modelo1$modelo <- with(tuneo_modelo1, reorder(modelo,tasa, mean))
ggplot(tuneo_modelo1, aes(x = modelo, y = tasa, col = rep)) +
geom_boxplot(alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo")
ggsave("./charts/gradient_boosting/modelo1/05_tasa_fallos_modelo1_10rep.png")
tuneo_modelo1$modelo <- with(tuneo_modelo1, reorder(modelo,auc, mean))
ggplot(tuneo_modelo1, aes(x = modelo, y = auc, col = rep)) +
geom_boxplot(alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo")
ggsave("./charts/gradient_boosting/modelo1/05_auc_modelo1_10rep.png")
tuneo_modelo2 <- rbind(tuneo_gradient_boosting_modelo2, tuneo_gradient_boosting_modelo2_10rep)
tuneo_modelo2$rep <- c(rep("5", 10), rep("10", 20))
tuneo_modelo2 <- rbind(tuneo_gradient_boosting_modelo2, tuneo_gradient_boosting_modelo2_10_rep)
tuneo_modelo2$rep <- c(rep("5", 10), rep("10", 20))
tuneo_modelo2$modelo <- with(tuneo_modelo2, reorder(modelo,tasa, mean))
ggplot(tuneo_modelo2, aes(x = modelo, y = tasa, col = rep)) +
geom_boxplot(alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo")
ggsave("./charts/gradient_boosting/modelo2/05_tasa_fallos_modelo2_10rep.png")
tuneo_modelo1$modelo <- with(tuneo_modelo2, reorder(modelo,auc, mean))
ggplot(tuneo_modelo2, aes(x = modelo, y = auc, col = rep)) +
geom_boxplot(alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo")
tuneo_modelo2$modelo <- with(tuneo_modelo2, reorder(modelo,auc, mean))
ggplot(tuneo_modelo2, aes(x = modelo, y = auc, col = rep)) +
geom_boxplot(alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo")
tuneo_modelo1$modelo <- with(tuneo_modelo1, reorder(modelo,tasa, mean))
ggplot(tuneo_modelo1, aes(x = modelo, y = tasa, col = rep)) +
geom_boxplot(alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo")
ggsave("./charts/gradient_boosting/modelo1/05_tasa_fallos_modelo1_10rep.png")
tuneo_modelo1$modelo <- with(tuneo_modelo1, reorder(modelo,auc, mean))
ggplot(tuneo_modelo1, aes(x = modelo, y = auc, col = rep)) +
geom_boxplot(alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("AUC por modelo")
ggsave("./charts/gradient_boosting/modelo1/05_auc_modelo1_10rep.png")
tuneo_modelo2$modelo <- with(tuneo_modelo2, reorder(modelo,tasa, mean))
ggplot(tuneo_modelo2, aes(x = modelo, y = tasa, col = rep)) +
geom_boxplot(alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo")
ggsave("./charts/gradient_boosting/modelo2/05_tasa_fallos_modelo2_10rep.png")
tuneo_modelo2$modelo <- with(tuneo_modelo2, reorder(modelo,auc, mean))
ggplot(tuneo_modelo2, aes(x = modelo, y = auc, col = rep)) +
geom_boxplot(alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("AUC por modelo")
ggsave("./charts/gradient_boosting/modelo2/05_auc_modelo2_10rep.png")
surgical_test_data <- fread("./data/surgical_test_data.csv", data.table = FALSE)
names(surgical_test_data)[35] <- "target"
surgical_test_data$target     <- as.factor(surgical_test_data$target)
control <- trainControl(method = "repeatedcv",number=5,repeats=10,
savePredictions = "all",classProbs=TRUE)
set.seed(1234)
gbm_modelo1_final <- train(as.formula(paste0(target, "~" , paste0(var_modelo1, collapse = "+"))),
data=surgical_dataset, method="gbm", trControl = control,tuneGrid = expand.grid(shrinkage=c(0.3),
n.minobsinnode=c(20),
n.trees=c(100)),
distribution="bernoulli", bag.fraction=0.5,verbose=FALSE)
set.seed(1234)
gbm_modelo2_final <- train(as.formula(paste0(target, "~" , paste0(var_modelo2, collapse = "+"))),
data=surgical_dataset, method="gbm", trControl = control,tuneGrid = expand.grid(shrinkage=c(0.3),
n.minobsinnode=c(20),
n.trees=c(100)),
distribution="bernoulli", bag.fraction=0.5,verbose=FALSE)
control <- trainControl(method = "repeatedcv",number=5,repeats=10,
savePredictions = "all",classProbs=TRUE)
set.seed(1234)
gbm_modelo1_final <- train(as.formula(paste0(target, "~" , paste0(var_modelo1, collapse = "+"))),
data=surgical_dataset, method="gbm", trControl = control,tuneGrid = expand.grid(shrinkage=c(0.3),
n.minobsinnode=c(20),
n.trees=c(100),
interaction.depth=c(2)),
distribution="bernoulli", bag.fraction=0.5,verbose=FALSE)
set.seed(1234)
gbm_modelo2_final <- train(as.formula(paste0(target, "~" , paste0(var_modelo2, collapse = "+"))),
data=surgical_dataset, method="gbm", trControl = control,tuneGrid = expand.grid(shrinkage=c(0.3),
n.minobsinnode=c(20),
n.trees=c(100),
interaction.depth=c(2)),
distribution="bernoulli", bag.fraction=0.5,verbose=FALSE)
matriz_conf_1 <- matriz_confusion_predicciones(gbm_modelo1_final, NULL, surgical_test_data, 0.5)
matriz_conf_2 <- matriz_confusion_predicciones(gbm_modelo2_final, NULL, surgical_test_data, 0.5)
matriz_conf_1
matriz_conf_2
gbm_modelo1_final
gbm_modelo1_final$results
tuneo_gradient_boosting_modelo1_10rep
tuneo_gradient_boosting_modelo2_10_rep
modelos_actuales <- as.data.frame(read_excel("./ComparativaModelos.xlsx",
sheet = "gradient_boosting"))
modelos_actuales$tasa <- as.numeric(modelos_actuales$tasa)
modelos_actuales$auc <- as.numeric(modelos_actuales$auc)
modelos_actuales$modelo <- with(modelos_actuales,
reorder(modelo,tasa, mean))
ggplot(modelos_actuales, aes(x = modelo, y = tasa)) +
geom_boxplot(fill =  "#4271AE", colour = "#1F3552",
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo")
ggplot(modelos_actuales, aes(x = modelo, y = tasa)) +
geom_boxplot(fill =  "#4271AE", colour = "#1F3552",
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo")
ggsave('./charts/comparativas/04_log_avnnet_bagging_rf_tasa.jpeg')
modelos_actuales$modelo <- with(modelos_actuales,
reorder(modelo,auc, mean))
ggplot(modelos_actuales, aes(x = modelo, y = auc)) +
geom_boxplot(fill =  "#4271AE", colour = "#1F3552",
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("AUC por modelo")
ggsave('./charts/comparativas/03_log_avnnet_bagging_rf_auc.jpeg')
modelos_actuales$modelo <- with(modelos_actuales,
reorder(modelo,tasa, mean))
ggplot(modelos_actuales, aes(x = modelo, y = tasa)) +
geom_boxplot(fill =  "#4271AE", colour = "#1F3552",
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo")
ggsave('./charts/comparativas/05_log_avnnet_bagging_rf_gbm_tasa.jpeg')
modelos_actuales$modelo <- with(modelos_actuales,
reorder(modelo,auc, mean))
ggplot(modelos_actuales, aes(x = modelo, y = auc)) +
geom_boxplot(fill =  "#4271AE", colour = "#1F3552",
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("AUC por modelo")
ggsave('./charts/comparativas/05_log_avnnet_bagging_rf_gbm_auc.jpeg')
#---- Detenemos el cluster
stopCluster(cluster)
#---- Guardamos el fichero RData
save.image(file = "./rdata/GradientBoosting.RData")
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/RandomForest.RData")
#-- ¿Y si lo probamos sin reemplazamiento? Probamos con el mejor modelo en terminos de AUC (modelo 1)
bagging_modelo_sin_reemp <- tuneo_bagging(surgical_dataset, target = target,
lista.continua = var_modelo1,
nodesizes = 20,
sampsizes = 1000, mtry = 3,
ntree = 2000, grupos = 5, repe = 10, replace = FALSE)
bagging_modelo_sin_reemp$modelo <- "RF. MODELO 1 (no reemp)"
modelos_actuales <- rbind(modelos_actuales, bagging_modelo_sin_reemp)
modelos_actuales$modelo <- with(modelos_actuales,
reorder(modelo,tasa, mean))
ggplot(modelos_actuales, aes(x = modelo, y = tasa)) +
geom_boxplot(fill =  "#4271AE", colour = "#1F3552",
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo")
ggsave('./charts/comparativas/03_log_avnnet_bagging_rf_tasa.jpeg')
modelos_actuales$modelo <- with(modelos_actuales,
reorder(modelo,auc, mean))
ggplot(modelos_actuales, aes(x = modelo, y = auc)) +
geom_boxplot(fill =  "#4271AE", colour = "#1F3552",
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("AUC por modelo")
ggsave('./charts/comparativas/03_log_avnnet_bagging_rf_auc.jpeg')
#-- Si hacemos zoom sobre los modelos bagging y rf...
modelos_actuales_zoomed <- modelos_actuales[modelos_actuales$modelo %in% c("BAG. MODELO 1", "BAG. MODELO 2", "RF. MODELO 1",
"RF. MODELO 2", "RF. MODELO 1 (no reemp)"), ]
modelos_actuales_zoomed$modelo <- with(modelos_actuales_zoomed,
reorder(modelo,tasa, mean))
ggplot(modelos_actuales_zoomed, aes(x = modelo, y = tasa)) +
geom_boxplot(fill =  "#4271AE", colour = "#1F3552",
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo (solo BAGGING)")
ggsave('./charts/random_forest/03_FINAL_tasa.jpeg')
modelos_actuales_zoomed$modelo <- with(modelos_actuales_zoomed,
reorder(modelo,auc, mean))
ggplot(modelos_actuales_zoomed, aes(x = modelo, y = auc)) +
geom_boxplot(fill =  "#4271AE", colour = "#1F3552",
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("AUC por modelo (solo BAGGING)")
ggsave('./charts/random_forest/03_FINAL_auc.jpeg')
# ------------- Random Forest ---------------
# Objetivo: elaborar el mejor modelo de Random Forest de acuerdo
#           a los valores de prediccion obtenidos tras variar los parametros
#           sampsize, nodesize y mtry
# Autor: Alberto Fernandez Hernandez
#--- Librerias
suppressPackageStartupMessages({
library(data.table)    # Lectura de ficheros mucho mas rapido que read.csv
library(parallel)      # Paralelizacion de funciones (I)
library(doParallel)    # Paralelizacion de funciones (II)
library(caret)         # Recursive Feature Elimination
library(randomForest)  # Seleccion del numero de arboles
library(readxl)        # Lectura de ficheros Excel
source("./librerias/librerias_propias.R")
})
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
#-- ¿Y si lo probamos sin reemplazamiento? Probamos con el mejor modelo en terminos de AUC (modelo 1)
bagging_modelo_sin_reemp <- tuneo_bagging(surgical_dataset, target = target,
lista.continua = var_modelo1,
nodesizes = 20,
sampsizes = 1000, mtry = 3,
ntree = 2000, grupos = 5, repe = 10, replace = FALSE)
bagging_modelo_sin_reemp$modelo <- "RF. MODELO 1 (no reemp)"
modelos_actuales <- rbind(modelos_actuales, bagging_modelo_sin_reemp)
modelos_actuales$modelo <- with(modelos_actuales,
reorder(modelo,tasa, mean))
ggplot(modelos_actuales, aes(x = modelo, y = tasa)) +
geom_boxplot(fill =  "#4271AE", colour = "#1F3552",
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo")
ggsave('./charts/comparativas/03_log_avnnet_bagging_rf_tasa.jpeg')
modelos_actuales$modelo <- with(modelos_actuales,
reorder(modelo,auc, mean))
ggplot(modelos_actuales, aes(x = modelo, y = auc)) +
geom_boxplot(fill =  "#4271AE", colour = "#1F3552",
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("AUC por modelo")
ggsave('./charts/comparativas/03_log_avnnet_bagging_rf_auc.jpeg')
#-- Si hacemos zoom sobre los modelos bagging y rf...
modelos_actuales_zoomed <- modelos_actuales[modelos_actuales$modelo %in% c("BAG. MODELO 1", "BAG. MODELO 2", "RF. MODELO 1",
"RF. MODELO 2", "RF. MODELO 1 (no reemp)"), ]
modelos_actuales_zoomed$modelo <- with(modelos_actuales_zoomed,
reorder(modelo,tasa, mean))
ggplot(modelos_actuales_zoomed, aes(x = modelo, y = tasa)) +
geom_boxplot(fill =  "#4271AE", colour = "#1F3552",
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo (solo BAGGING)")
ggsave('./charts/random_forest/03_FINAL_tasa.jpeg')
modelos_actuales_zoomed$modelo <- with(modelos_actuales_zoomed,
reorder(modelo,auc, mean))
ggplot(modelos_actuales_zoomed, aes(x = modelo, y = auc)) +
geom_boxplot(fill =  "#4271AE", colour = "#1F3552",
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("AUC por modelo (solo BAGGING)")
ggsave('./charts/random_forest/03_FINAL_auc.jpeg')
stopCluster(cluster)
#---- Guardamos el fichero RData
save.image(file = "./rdata/RandomForest.RData")
load("~/UCM/Machine Learning/Practica ML/MachineLearning/rdata/Bagging.RData")
# ------------- Bagging ---------------
# Objetivo: elaborar el mejor modelo de bagging de acuerdo
#           a los valores de prediccion obtenidos tras variar los parametros
#           sampsize,
# Autor: Alberto Fernandez Hernandez
#--- Librerias
suppressPackageStartupMessages({
library(data.table)      # Lectura de ficheros mucho mas rapido que read.csv
library(parallel)        # Paralelizacion de funciones (I)
library(doParallel)      # Paralelizacion de funciones (II)
library(caret)           # Recursive Feature Elimination
library(randomForest)    # Seleccion del numero de arboles
library(readxl)          # Lectura de ficheros Excel
library(randomForestSRC) # Tuneado random forest
source("./librerias/librerias_propias.R")
})
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
modelos_actuales <- as.data.frame(read_excel("./ComparativaModelos.xlsx",
sheet = "bagging"))
modelos_actuales$tasa <- as.numeric(modelos_actuales$tasa)
modelos_actuales$auc <- as.numeric(modelos_actuales$auc)
#-- ¿Y si lo probamos sin reemplazamiento? Probamos con el mejor modelo en terminos de AUC (modelo 1)
bagging_modelo_sin_reemp <- tuneo_bagging(surgical_dataset, target = target,
lista.continua = var_modelo1,
nodesizes = 20,
sampsizes = 1000, mtry = mtry.1,
ntree = n.trees.1, grupos = 5, repe = 10, replace = FALSE)
bagging_modelo_sin_reemp$modelo <- "BAG. MODELO 1 (no reemp)"
modelos_actuales <- rbind(modelos_actuales, bagging_modelo_sin_reemp)
modelos_actuales$modelo <- with(modelos_actuales,
reorder(modelo,tasa, mean))
ggplot(modelos_actuales, aes(x = modelo, y = tasa)) +
geom_boxplot(fill =  "#4271AE", colour = "#1F3552",
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo")
ggsave('./charts/comparativas/03_log_avnnet_bagging_tasa.jpeg')
modelos_actuales$modelo <- with(modelos_actuales,
reorder(modelo,auc, mean))
ggplot(modelos_actuales, aes(x = modelo, y = auc)) +
geom_boxplot(fill =  "#4271AE", colour = "#1F3552",
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("AUC por modelo")
ggsave('./charts/comparativas/03_log_avnnet_bagging_auc.jpeg')
#-- Si hacemos zoom sobre los modelos bagging...
modelos_actuales_zoomed <- modelos_actuales[modelos_actuales$modelo %in% c("BAG. MODELO 1", "BAG. MODELO 2", "BAG. MODELO 1 (no reemp)"), ]
modelos_actuales_zoomed$modelo <- with(modelos_actuales_zoomed,
reorder(modelo,tasa, mean))
ggplot(modelos_actuales_zoomed, aes(x = modelo, y = tasa)) +
geom_boxplot(fill =  "#4271AE", colour = "#1F3552",
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("Tasa de fallos por modelo (solo BAGGING)")
ggsave('./charts/bagging/03_FINAL_tasa.jpeg')
modelos_actuales_zoomed$modelo <- with(modelos_actuales_zoomed,
reorder(modelo,auc, mean))
ggplot(modelos_actuales_zoomed, aes(x = modelo, y = auc)) +
geom_boxplot(fill =  "#4271AE", colour = "#1F3552",
alpha = 0.7) +
scale_x_discrete(name = "Modelo") +
ggtitle("AUC por modelo (solo BAGGING)")
ggsave('./charts/bagging/03_FINAL_auc.jpeg')
#---- Detenemos el cluster
stopCluster(cluster)
#---- Guardamos el fichero RData
save.image(file = "./rdata/Bagging.RData")
